{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiomics BMI Paper — Longitudinal BMI Predictions from the Arivale Time-series Omics Using the Baseline LASSO Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***by Kengo Watanabe***  \n",
    "\n",
    "This Jupyter Notebook (with Python 3 kernel) calculated longitudinal BMI predictions from each of the Arivale time-series blood omic datasets, using the LASSO linear regression models that were fitted on the Arivale baseline datasets.  \n",
    "\n",
    "Input files:  \n",
    "* Arivale baseline BMI and blood omics (preprocessed): 210104_Biological-BMI-paper_RF-imputation_baseline-\\[metDF/protDF/chemDF/combiDF\\]-with-RF-imputation.tsv  \n",
    "* Arivale time-series blood omics (preprocessed): 220804_Multiomics-BMI-NatMed1stRevision_RF-imputation-ver2_time-series-\\[metDF/protDF/chemDF/combiDF\\]-with-RF-imputation.tsv  \n",
    "* Baseline biological BMI models: 220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_\\[MetBMI/ProtBMI/ChemBMI/CombiBMI\\]-\\[Female/Male/BothSex\\]-LASSObcoefs.tsv  \n",
    "* Arivale baseline BMI predictions: 220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_\\[MetBMI/ProtBMI/ChemBMI/CombiBMI\\]-\\[Female/Male/BothSex\\].tsv  \n",
    "\n",
    "Output figures and tables:  \n",
    "* Intermediate tables for other notebooks (BMI predictions)  \n",
    "\n",
    "Original notebook (memo for my future tracing):  \n",
    "* dalek:\\[JupyterLab HOME\\]/220621_Multiomics-BMI-NatMedRevision/220805_Multiomics-BMI-NatMed1stRevision_BMI-longitudinal-LASSO.ipynb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/conda/envs/arivale-py3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\n",
      "_openmp_mutex             4.5                       1_gnu    conda-forge\n",
      "analytics                 0.1                      pypi_0    pypi\n",
      "argon2-cffi               21.1.0           py39h3811e60_0    conda-forge\n",
      "arivale-data-interface    0.1.0                    pypi_0    pypi\n",
      "async_generator           1.10                       py_0    conda-forge\n",
      "atk-1.0                   2.36.0               h3371d22_4    conda-forge\n",
      "attrs                     21.2.0             pyhd8ed1ab_0    conda-forge\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\n",
      "backports                 1.0                        py_2    conda-forge\n",
      "backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\n",
      "biopython                 1.79             py39h3811e60_0    conda-forge\n",
      "bleach                    4.1.0              pyhd8ed1ab_0    conda-forge\n",
      "bokeh                     2.4.1            py39hf3d152e_1    conda-forge\n",
      "boto                      2.49.0                     py_0    conda-forge\n",
      "boto3                     1.19.2                   pypi_0    pypi\n",
      "botocore                  1.22.2                   pypi_0    pypi\n",
      "brotlipy                  0.7.0           py39h3811e60_1001    conda-forge\n",
      "bzip2                     1.0.8                h7f98852_4    conda-forge\n",
      "c-ares                    1.17.2               h7f98852_0    conda-forge\n",
      "ca-certificates           2022.6.15            ha878542_0    conda-forge\n",
      "cachecontrol              0.12.6                     py_0    conda-forge\n",
      "cairo                     1.16.0            h6cf1ce9_1008    conda-forge\n",
      "certifi                   2022.6.15        py39hf3d152e_0    conda-forge\n",
      "cffi                      1.14.6           py39h4bc2ebd_1    conda-forge\n",
      "chardet                   4.0.0            py39hf3d152e_1    conda-forge\n",
      "charset-normalizer        2.0.0              pyhd8ed1ab_0    conda-forge\n",
      "click                     8.0.3            py39hf3d152e_0    conda-forge\n",
      "colorama                  0.4.4              pyh9f0ad1d_0    conda-forge\n",
      "cryptography              35.0.0           py39h95dcef6_1    conda-forge\n",
      "cycler                    0.10.0                     py_2    conda-forge\n",
      "cython                    0.29.24          py39he80948d_0    conda-forge\n",
      "debugpy                   1.4.1            py39he80948d_0    conda-forge\n",
      "decorator                 4.4.2                      py_0    conda-forge\n",
      "defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\n",
      "english                   2020.7.0           pyhd8ed1ab_0    conda-forge\n",
      "entrypoints               0.3             py39hde42818_1002    conda-forge\n",
      "et_xmlfile                1.0.1                   py_1001    conda-forge\n",
      "expat                     2.4.1                h9c3ff4c_0    conda-forge\n",
      "font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge\n",
      "font-ttf-inconsolata      3.000                h77eed37_0    conda-forge\n",
      "font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge\n",
      "font-ttf-ubuntu           0.83                 hab24e00_0    conda-forge\n",
      "fontconfig                2.13.1            hba837de_1005    conda-forge\n",
      "fonts-conda-ecosystem     1                             0    conda-forge\n",
      "fonts-conda-forge         1                             0    conda-forge\n",
      "freetype                  2.10.4               h0708190_1    conda-forge\n",
      "fribidi                   1.0.10               h36c2ea0_0    conda-forge\n",
      "future                    0.18.2           py39hf3d152e_3    conda-forge\n",
      "gdk-pixbuf                2.42.6               h04a7f16_0    conda-forge\n",
      "gettext                   0.19.8.1          h73d1719_1008    conda-forge\n",
      "giflib                    5.2.1                h36c2ea0_2    conda-forge\n",
      "graphite2                 1.3.13            h58526e2_1001    conda-forge\n",
      "graphviz                  2.49.1               h85b4f2f_0    conda-forge\n",
      "gtk2                      2.24.33              h539f30e_1    conda-forge\n",
      "gts                       0.7.6                h64030ff_2    conda-forge\n",
      "harfbuzz                  3.0.0                h83ec7ef_1    conda-forge\n",
      "hdmedians                 0.14.2           py39hce5d2b2_0    conda-forge\n",
      "icu                       68.1                 h58526e2_0    conda-forge\n",
      "idna                      3.1                pyhd3deb0d_0    conda-forge\n",
      "importlib-metadata        4.8.1            py39hf3d152e_0    conda-forge\n",
      "iniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge\n",
      "interchange               2021.0.4           pyhd8ed1ab_0    conda-forge\n",
      "ipykernel                 6.4.2            py39hef51801_0    conda-forge\n",
      "ipython                   7.28.0           py39hef51801_0    conda-forge\n",
      "ipython_genutils          0.2.0                      py_1    conda-forge\n",
      "ipywidgets                7.6.5              pyhd8ed1ab_0    conda-forge\n",
      "jbig                      2.1               h7f98852_2003    conda-forge\n",
      "jedi                      0.18.0           py39hf3d152e_2    conda-forge\n",
      "jinja2                    3.0.2              pyhd8ed1ab_0    conda-forge\n",
      "jmespath                  0.10.0                   pypi_0    pypi\n",
      "joblib                    1.1.0              pyhd8ed1ab_0    conda-forge\n",
      "jpeg                      9d                   h36c2ea0_0    conda-forge\n",
      "jsonschema                4.1.2              pyhd8ed1ab_0    conda-forge\n",
      "jupyter_client            7.0.6              pyhd8ed1ab_0    conda-forge\n",
      "jupyter_core              4.8.1            py39hf3d152e_0    conda-forge\n",
      "jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\n",
      "jupyterlab_widgets        1.0.2              pyhd8ed1ab_0    conda-forge\n",
      "kiwisolver                1.3.2            py39h1a9c180_0    conda-forge\n",
      "krb5                      1.19.2               hcc1bbae_2    conda-forge\n",
      "lcms2                     2.12                 hddcbb42_0    conda-forge\n",
      "ld_impl_linux-64          2.36.1               hea4e1c9_2    conda-forge\n",
      "lerc                      2.2.1                h9c3ff4c_0    conda-forge\n",
      "libblas                   3.9.0           12_linux64_openblas    conda-forge\n",
      "libcblas                  3.9.0           12_linux64_openblas    conda-forge\n",
      "libcurl                   7.79.1               h2574ce0_1    conda-forge\n",
      "libdeflate                1.7                  h7f98852_5    conda-forge\n",
      "libedit                   3.1.20191231         he28a2e2_2    conda-forge\n",
      "libev                     4.33                 h516909a_1    conda-forge\n",
      "libffi                    3.4.2                h9c3ff4c_4    conda-forge\n",
      "libgcc-ng                 11.2.0              h1d223b6_11    conda-forge\n",
      "libgd                     2.3.3                h6ad9fb6_0    conda-forge\n",
      "libgfortran-ng            11.2.0              h69a702a_11    conda-forge\n",
      "libgfortran5              11.2.0              h5c6108e_11    conda-forge\n",
      "libglib                   2.70.0               h174f98d_1    conda-forge\n",
      "libgomp                   11.2.0              h1d223b6_11    conda-forge\n",
      "libiconv                  1.16                 h516909a_0    conda-forge\n",
      "liblapack                 3.9.0           12_linux64_openblas    conda-forge\n",
      "libnghttp2                1.43.0               h812cca2_1    conda-forge\n",
      "libopenblas               0.3.18          pthreads_h8fe5266_0    conda-forge\n",
      "libpng                    1.6.37               h21135ba_2    conda-forge\n",
      "libpq                     13.3                 hd57d9b9_1    conda-forge\n",
      "librsvg                   2.52.2               hc3c00ef_0    conda-forge\n",
      "libsodium                 1.0.18               h36c2ea0_1    conda-forge\n",
      "libssh2                   1.10.0               ha56f1ee_2    conda-forge\n",
      "libstdcxx-ng              11.2.0              he4da1e4_11    conda-forge\n",
      "libtiff                   4.3.0                hf544144_1    conda-forge\n",
      "libtool                   2.4.6             h9c3ff4c_1008    conda-forge\n",
      "libuuid                   2.32.1            h7f98852_1000    conda-forge\n",
      "libwebp                   1.2.1                h3452ae3_0    conda-forge\n",
      "libwebp-base              1.2.1                h7f98852_0    conda-forge\n",
      "libxcb                    1.13              h7f98852_1003    conda-forge\n",
      "libxml2                   2.9.12               h72842e0_0    conda-forge\n",
      "libxslt                   1.1.33               h15afd5d_2    conda-forge\n",
      "libzlib                   1.2.11            h36c2ea0_1013    conda-forge\n",
      "lockfile                  0.12.2                     py_1    conda-forge\n",
      "lxml                      4.6.3            py39h107f48f_0    conda-forge\n",
      "lz4-c                     1.9.3                h9c3ff4c_1    conda-forge\n",
      "markupsafe                2.0.1            py39h3811e60_0    conda-forge\n",
      "matplotlib-base           3.4.3            py39h2fa2bec_1    conda-forge\n",
      "matplotlib-inline         0.1.3              pyhd8ed1ab_0    conda-forge\n",
      "matplotlib-venn           0.11.7             pyhd8ed1ab_0    conda-forge\n",
      "missingpy                 0.2.0                    pypi_0    pypi\n",
      "mistune                   0.8.4           py39h3811e60_1004    conda-forge\n",
      "more-itertools            8.10.0             pyhd8ed1ab_0    conda-forge\n",
      "mscorefonts               0.0.1                         3    conda-forge\n",
      "msgpack-python            1.0.2            py39h1a9c180_1    conda-forge\n",
      "natsort                   7.1.1              pyhd8ed1ab_0    conda-forge\n",
      "nbclient                  0.5.4              pyhd8ed1ab_0    conda-forge\n",
      "nbconvert                 6.2.0            py39hf3d152e_0    conda-forge\n",
      "nbformat                  5.1.3              pyhd8ed1ab_0    conda-forge\n",
      "ncurses                   6.2                  h58526e2_4    conda-forge\n",
      "neo4j-python-driver       4.3.7              pyhd8ed1ab_0    conda-forge\n",
      "neobolt                   1.7.17           py39h3811e60_2    conda-forge\n",
      "neotime                   1.7.4                      py_0    conda-forge\n",
      "nest-asyncio              1.5.1              pyhd8ed1ab_0    conda-forge\n",
      "networkx                  2.6.3              pyhd8ed1ab_0    conda-forge\n",
      "notebook                  6.4.5              pyha770c72_0    conda-forge\n",
      "numpy                     1.21.3           py39hdbf815f_0    conda-forge\n",
      "olefile                   0.46               pyh9f0ad1d_1    conda-forge\n",
      "openjpeg                  2.4.0                hb52868f_1    conda-forge\n",
      "openpyxl                  3.0.9              pyhd8ed1ab_0    conda-forge\n",
      "openssl                   1.1.1o               h166bdaf_0    conda-forge\n",
      "packaging                 21.0               pyhd8ed1ab_0    conda-forge\n",
      "pandas                    1.3.4            py39hde0f152_0    conda-forge\n",
      "pandoc                    2.15                 h7f98852_0    conda-forge\n",
      "pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\n",
      "pango                     1.48.10              h54213e6_2    conda-forge\n",
      "parso                     0.8.2              pyhd8ed1ab_0    conda-forge\n",
      "patsy                     0.5.2              pyhd8ed1ab_0    conda-forge\n",
      "pcre                      8.45                 h9c3ff4c_0    conda-forge\n",
      "pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\n",
      "pickleshare               0.7.5           py39hde42818_1002    conda-forge\n",
      "pillow                    8.3.2            py39ha612740_0    conda-forge\n",
      "pip                       21.3.1             pyhd8ed1ab_0    conda-forge\n",
      "pixman                    0.40.0               h36c2ea0_0    conda-forge\n",
      "plotly                    5.3.1              pyhd8ed1ab_0    conda-forge\n",
      "pluggy                    1.0.0            py39hf3d152e_1    conda-forge\n",
      "prometheus_client         0.11.0             pyhd8ed1ab_0    conda-forge\n",
      "prompt-toolkit            3.0.21             pyha770c72_0    conda-forge\n",
      "prompt_toolkit            3.0.21               hd8ed1ab_0    conda-forge\n",
      "psycopg2                  2.9.1            py39h3811e60_0    conda-forge\n",
      "pthread-stubs             0.4               h36c2ea0_1001    conda-forge\n",
      "ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\n",
      "py                        1.10.0             pyhd3deb0d_0    conda-forge\n",
      "py2neo                    2021.2.3           pyhd8ed1ab_0    conda-forge\n",
      "pycparser                 2.20               pyh9f0ad1d_2    conda-forge\n",
      "pygments                  2.10.0             pyhd8ed1ab_0    conda-forge\n",
      "pygraphviz                1.7              py39h78163bd_0    conda-forge\n",
      "pyopenssl                 21.0.0             pyhd8ed1ab_0    conda-forge\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\n",
      "pyrsistent                0.17.3           py39h3811e60_2    conda-forge\n",
      "pysam                     0.17.0           py39h051187c_0    bioconda\n",
      "pysocks                   1.7.1            py39hf3d152e_3    conda-forge\n",
      "pytabix                   0.1              py39h98c8e45_1    bioconda\n",
      "pytest                    6.2.5            py39hf3d152e_0    conda-forge\n",
      "python                    3.9.7           hb7a2778_3_cpython    conda-forge\n",
      "python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\n",
      "python-graphviz           0.17               pyhaef67bd_0    conda-forge\n",
      "python_abi                3.9                      2_cp39    conda-forge\n",
      "pytz                      2021.3             pyhd8ed1ab_0    conda-forge\n",
      "pyvcf                     0.6.8           py39hde42818_1002    conda-forge\n",
      "pyyaml                    6.0              py39h3811e60_0    conda-forge\n",
      "pyzmq                     22.3.0           py39h37b5a0c_0    conda-forge\n",
      "readline                  8.1                  h46c0cb4_0    conda-forge\n",
      "requests                  2.26.0             pyhd8ed1ab_0    conda-forge\n",
      "s3transfer                0.5.0                    pypi_0    pypi\n",
      "scikit-bio                0.5.6            py39h16ac069_4    conda-forge\n",
      "scikit-learn              1.0.1            py39h7c5d8c9_0    conda-forge\n",
      "scipy                     1.7.1            py39hee8e79c_0    conda-forge\n",
      "seaborn                   0.11.2               hd8ed1ab_0    conda-forge\n",
      "seaborn-base              0.11.2             pyhd8ed1ab_0    conda-forge\n",
      "send2trash                1.8.0              pyhd8ed1ab_0    conda-forge\n",
      "setuptools                58.2.0           py39hf3d152e_0    conda-forge\n",
      "six                       1.16.0             pyh6c4a22f_0    conda-forge\n",
      "sqlite                    3.36.0               h9cd32fc_2    conda-forge\n",
      "statsmodels               0.13.0           py39hce5d2b2_0    conda-forge\n",
      "tenacity                  8.0.1              pyhd8ed1ab_0    conda-forge\n",
      "terminado                 0.12.1           py39hf3d152e_0    conda-forge\n",
      "testpath                  0.5.0              pyhd8ed1ab_0    conda-forge\n",
      "threadpoolctl             3.0.0              pyh8a188c0_0    conda-forge\n",
      "tk                        8.6.11               h27826a3_1    conda-forge\n",
      "toml                      0.10.2             pyhd8ed1ab_0    conda-forge\n",
      "tornado                   6.1              py39h3811e60_1    conda-forge\n",
      "traitlets                 5.1.0              pyhd8ed1ab_0    conda-forge\n",
      "typing_extensions         3.10.0.2           pyha770c72_0    conda-forge\n",
      "tzdata                    2021e                he74cb21_0    conda-forge\n",
      "urllib3                   1.26.7             pyhd8ed1ab_0    conda-forge\n",
      "venn                      0.1.3                    pypi_0    pypi\n",
      "wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\n",
      "webencodings              0.5.1                      py_1    conda-forge\n",
      "wheel                     0.37.0             pyhd8ed1ab_1    conda-forge\n",
      "widgetsnbextension        3.5.1            py39hf3d152e_4    conda-forge\n",
      "wordcloud                 1.8.1                    pypi_0    pypi\n",
      "xlrd                      2.0.1              pyhd8ed1ab_3    conda-forge\n",
      "xorg-kbproto              1.0.7             h7f98852_1002    conda-forge\n",
      "xorg-libice               1.0.10               h7f98852_0    conda-forge\n",
      "xorg-libsm                1.2.3             hd9c2040_1000    conda-forge\n",
      "xorg-libx11               1.7.2                h7f98852_0    conda-forge\n",
      "xorg-libxau               1.0.9                h7f98852_0    conda-forge\n",
      "xorg-libxdmcp             1.1.3                h7f98852_0    conda-forge\n",
      "xorg-libxext              1.3.4                h7f98852_1    conda-forge\n",
      "xorg-libxrender           0.9.10            h7f98852_1003    conda-forge\n",
      "xorg-renderproto          0.11.1            h7f98852_1002    conda-forge\n",
      "xorg-xextproto            7.3.0             h7f98852_1002    conda-forge\n",
      "xorg-xproto               7.0.31            h7f98852_1007    conda-forge\n",
      "xz                        5.2.5                h516909a_1    conda-forge\n",
      "yaml                      0.2.5                h516909a_0    conda-forge\n",
      "zeromq                    4.3.4                h9c3ff4c_1    conda-forge\n",
      "zipp                      3.6.0              pyhd8ed1ab_0    conda-forge\n",
      "zlib                      1.2.11            h36c2ea0_1013    conda-forge\n",
      "zstd                      1.5.0                ha95c52a_0    conda-forge\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "#For Arial font\n",
    "#!conda install -c conda-forge -y mscorefonts\n",
    "##-> The below was also needed in matplotlib 3.4.2\n",
    "#import shutil\n",
    "#import matplotlib\n",
    "#shutil.rmtree(matplotlib.get_cachedir())\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "!conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cohort preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following code is completely same with the one used in the baseline LASSO modeling. Hence, the correspondence between participant and testing (hold-out) set for each LASSO model is maintained.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Import the cleaned dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Omics dataframes are imported at each section later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the baseline BMI dataframe\n",
    "fileDir = '../210104_Biological-BMI-paper/ExportData/'\n",
    "ipynbName = '210104_Biological-BMI-paper_RF-imputation_'\n",
    "fileName = 'baseline-combiDF-with-RF-imputation.tsv'\n",
    "tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id': str})\n",
    "tempDF = tempDF.set_index('public_client_id')\n",
    "##Take BMI and general covariates (without Race in this study)\n",
    "tempL = ['log_BaseBMI', 'Sex', 'BaseAge', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5']\n",
    "tempDF = tempDF[tempL]\n",
    "\n",
    "display(tempDF)\n",
    "\n",
    "bmiDF = tempDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Stratification with sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stratify the cohort with sex\n",
    "bmiDF_F = bmiDF.loc[bmiDF['Sex']=='F']\n",
    "bmiDF_M = bmiDF.loc[bmiDF['Sex']=='M']\n",
    "bmiDF_B = bmiDF#Not copy just rename\n",
    "print('Female, Male, Both sex = ', len(bmiDF_F), ', ', len(bmiDF_M), ', ', len(bmiDF_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Split the cohort into 10 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "nmodels = 10\n",
    "tempD2 = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    #Split cohort to define the training and testing (hold-out) sets\n",
    "    tempL = np.array_split(tempDF, nmodels)#List of DFs\n",
    "    tempD = {}\n",
    "    for model_k in range(nmodels):\n",
    "        tempDF1 = tempL[model_k]\n",
    "        model_n = 'Model_'+str(model_k+1).zfill(2)\n",
    "        tempS = pd.Series(np.repeat(model_n, len(tempDF1)),\n",
    "                          index=tempDF1.index, name='Testing')\n",
    "        tempD[model_k] = tempS\n",
    "    tempS = pd.concat(list(tempD.values()), axis=0)\n",
    "    #Add the info to bmiDF\n",
    "    tempDF = pd.merge(tempDF, tempS, left_index=True, right_index=True, how='left')\n",
    "    tempD2[sex] = tempDF\n",
    "    print(sex)\n",
    "    display(tempDF)\n",
    "    display(tempDF['Testing'].value_counts())\n",
    "    print('')\n",
    "#Update\n",
    "bmiDF_F = tempD2['Female']\n",
    "bmiDF_M = tempD2['Male']\n",
    "bmiDF_B = tempD2['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metabolomics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Prepare the cleaned omics dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Because the fitted models are used for predictions, the dependent variable (BMI) is not needed. (Of note, BMI was not necessarily available for the same point of omics measurements.) However, not only the time-series but also the baseline omics DF needs to be prepared for standardization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = 'metDF'\n",
    "\n",
    "#Import the cleaned baseline omics dataframes\n",
    "fileDir = '../210104_Biological-BMI-paper/ExportData/'\n",
    "ipynbName = '210104_Biological-BMI-paper_RF-imputation_'\n",
    "fileName = 'baseline-'+df_n+'-with-RF-imputation.tsv'\n",
    "tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id': str})\n",
    "tempDF = tempDF.set_index('public_client_id')\n",
    "print(df_n+' original shape:', tempDF.shape)\n",
    "\n",
    "#Drop BMI and covariates\n",
    "tempL = ['log_BaseBMI', 'Sex', 'BaseAge', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Race']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF)\n",
    "\n",
    "baseDF = tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = 'metDF'\n",
    "\n",
    "#Import the cleaned time-series omics dataframes\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220804_Multiomics-BMI-NatMed1stRevision_RF-imputation-ver2_'\n",
    "fileName = 'time-series-'+df_n+'-with-RF-imputation.tsv'\n",
    "tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id': str})\n",
    "tempDF = tempDF.set_index('KeyIndex')\n",
    "tempDF = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "print(df_n+' original shape:', tempDF.shape)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "\n",
    "#Drop BMI and covariates\n",
    "tempL = ['log_BaseBMI', 'Sex', 'BaseAge', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Race']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "\n",
    "tsDF = tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check consistency\n",
    "print('Baseline DF:')\n",
    "display(baseDF.describe())\n",
    "print('Baseline from the time-series DF:')\n",
    "tempDF = tsDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "tempDF = tempDF.drop_duplicates('public_client_id', keep='first')\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> Confirmed that the baseline measurements were consistent after the improved imputation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Standarization with the baseline distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "\n",
    "#Check just in case\n",
    "tempA1 = baseDF.columns.to_numpy()\n",
    "tempA2 = tsDF.drop(columns=tempL).columns.to_numpy()\n",
    "print('nVariables is consistent between baseline and time-series DFs:',\n",
    "      len(tempA1)==len(tempA2))\n",
    "print('Variable order is consistent between baseline and time-series DFs:',\n",
    "      (tempA1==tempA2).sum()==len(tempA1))\n",
    "\n",
    "tempD2 = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    tempL1 = tempDF.index.tolist()\n",
    "    #Prepare baseline DF\n",
    "    tempDF1 = baseDF.loc[tempL1]\n",
    "    #Compute the mean and std for Z-score transformation based on the baseline distribution\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    scaler.fit(tempDF1)#Column direction\n",
    "    #Z-score transformation of the baseline DF (just for confirmation)\n",
    "    tempA = scaler.transform(tempDF1)\n",
    "    tempDF1 = pd.DataFrame(data=tempA, index=tempDF1.index, columns=tempDF1.columns)\n",
    "    \n",
    "    #Prepare time-series DF\n",
    "    tempDF2 = tsDF.loc[tsDF['public_client_id'].isin(tempL1)]\n",
    "    tempDF = tempDF2.drop(columns=tempL)\n",
    "    #Z-score transformation of the time-series DF with the baseline distribution\n",
    "    tempA = scaler.transform(tempDF)\n",
    "    tempDF = pd.DataFrame(data=tempA, index=tempDF.index, columns=tempDF.columns)\n",
    "    #Recover the time-series metadata\n",
    "    tempDF2 = tempDF2[tempL]\n",
    "    tempDF2 = pd.merge(tempDF2, tempDF, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    print(sex)\n",
    "    display(tempDF2)\n",
    "    tempD2[sex] = tempDF2\n",
    "    \n",
    "    #Confirmation\n",
    "    tempD = {'Baseline DF':tempDF1, 'Time-series DF':tempDF2}\n",
    "    for df_n in tempD.keys():\n",
    "        tempDF = tempD[df_n]\n",
    "        print(' - '+df_n, tempDF.shape)\n",
    "        if df_n=='Time-series DF':\n",
    "            print('    -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "            tempDF = tempDF.drop(columns=tempL)\n",
    "        display(tempDF.describe())\n",
    "        sns.set(style='ticks', font='Arial', context='notebook')\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        for col_i in range(3):\n",
    "            sns.distplot(tempDF.iloc[:, col_i], label=tempDF.columns[col_i])\n",
    "        sns.despine()\n",
    "        plt.xlabel(r'$Z$'+'-score')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend(bbox_to_anchor=(1, 0.5), loc='center left', borderaxespad=1)\n",
    "        plt.show()\n",
    "    print('')\n",
    "\n",
    "tsDF_F = tempD2['Female']\n",
    "tsDF_M = tempD2['Male']\n",
    "tsDF_B = tempD2['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> Confirmed that the baseline summary was completely same with the before (the baseline LASSO modeling).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Import the fitted LASSO models with the baseline measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar_model = 'MetBMI'\n",
    "tempD = {}\n",
    "for sex in ['Female', 'Male', 'BothSex']:\n",
    "    #Import the LASSO beta-coefficients (including intercept)\n",
    "    fileDir = './ExportData/'\n",
    "    ipynbName = '220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_'\n",
    "    fileName = yvar_model+'-'+sex+'-LASSObcoefs.tsv'\n",
    "    tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t').set_index('Variable')\n",
    "    #Drop summary columns\n",
    "    tempL = ['Mean', 'SD', 'nZeros']\n",
    "    tempDF = tempDF.drop(columns=tempL)\n",
    "    tempD[sex] = tempDF\n",
    "    \n",
    "    #Check\n",
    "    print(sex+':')\n",
    "    print(' - Variables (without intercept):', len(tempDF)-1)\n",
    "    display(tempDF)\n",
    "    print('')\n",
    "\n",
    "modelDF_F = tempD['Female']\n",
    "modelDF_M = tempD['Male']\n",
    "modelDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Calculate predictions using the fitted models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> According to LassoCV source, the self.predict(X) method calls self._decision_function(X) method, which further returns “safe_sparsedot(X, self.coef.T, denseoutput=True) + self.intercept\". In this case, safe_sparse_dot() simply corresponds to a dot product. Hence, manual calculation from beta-coefficients and intercept is impremented here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':tsDF_F, 'Male':tsDF_M, 'BothSex':tsDF_B}\n",
    "tempD2 = {'Female':modelDF_F, 'Male':modelDF_M, 'BothSex':modelDF_B}\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    tempDF1 = tempDF.drop(columns=tempL)\n",
    "    tempDF2 = tempD2[sex]\n",
    "    \n",
    "    #Add dummy intercept variable to data DF\n",
    "    tempDF1['Intercept'] = 1.0\n",
    "    \n",
    "    #Check just in case\n",
    "    tempA1 = tempDF1.columns.to_numpy()\n",
    "    tempA2 = tempDF2.index.to_numpy()\n",
    "    print(sex)\n",
    "    print(' - nVariables is consistent between data and model DFs:',\n",
    "          len(tempA1)==len(tempA2))\n",
    "    print(' - Variable order is consistent between data and model DFs:',\n",
    "          (tempA1==tempA2).sum()==len(tempA1))\n",
    "    \n",
    "    #Calculate prediction\n",
    "    tempA = np.dot(tempDF1, tempDF2)\n",
    "    tempDF1 = pd.DataFrame(tempA, index=tempDF1.index, columns=tempDF2.columns)\n",
    "    \n",
    "    #Recover the time-series metadata\n",
    "    tempDF = tempDF[tempL]\n",
    "    tempDF = pd.merge(tempDF, tempDF1, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    tempD[sex] = tempDF\n",
    "    display(tempDF)\n",
    "    print('')\n",
    "\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To obtain one single prediction for each participant and each time point, the calculated predictions from each model can be averaged.  \n",
    "> ***–> However, in addition to the overfitting problem for the baseline predictions, there is a potential risk of data leakage even for the longitudinal predictions.***  \n",
    "> –> In this version, one single prediction for each participant and each time point is selected with the prediction from the model for which the participant was included in the baseline testing (hold-out) set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "tempD2 = {'Female':predictDF_F, 'Male':predictDF_M, 'BothSex':predictDF_B}\n",
    "yvar_model = 'MetBMI'\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    #Retrieve the predictions for the testing (hold-out) set\n",
    "    tempDF = tempD1[sex]\n",
    "    tempS = tempDF['Testing']\n",
    "    tempDF = tempD2[sex]\n",
    "    tempDF = pd.merge(tempDF, tempS, left_on='public_client_id', right_index=True, how='left')\n",
    "    tempL = []\n",
    "    for row_i in range(len(tempDF)):\n",
    "        model_n = tempDF['Testing'].iloc[row_i]\n",
    "        tempL.append(tempDF[model_n].iloc[row_i])\n",
    "    tempDF['log_'+yvar_model] = tempL\n",
    "    \n",
    "    #Drop the temporal prediction columns\n",
    "    tempDF = tempDF.loc[:, ~tempDF.columns.str.contains('Model_')]\n",
    "    \n",
    "    #Convert to original scale\n",
    "    tempDF[yvar_model] = np.e**tempDF['log_'+yvar_model]\n",
    "    \n",
    "    tempD[sex] = tempDF\n",
    "    print(sex)\n",
    "    display(tempDF)\n",
    "    print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "    print('')\n",
    "#Update\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5. Clean and save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the baseline info\n",
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'BothSex':predictDF_B}\n",
    "tempD2 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "yvar_model = 'MetBMI'\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    \n",
    "    #Retrieve the baseline predictions\n",
    "    tempDF1 = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "    tempDF1 = tempDF1.drop_duplicates('public_client_id', keep='first')\n",
    "    tempDF1 = tempDF1.reset_index().set_index('public_client_id')\n",
    "    tempDF1 = tempDF1.rename(columns={yvar_model:'Base'+yvar_model})\n",
    "    \n",
    "    #Add baseline BMI and covariate info\n",
    "    tempDF2 = tempD2[sex]\n",
    "    ##Replace the log-scaled BMI with the original scaled\n",
    "    tempS = np.e**tempDF2['log_BaseBMI']\n",
    "    tempS.name = 'BaseBMI'\n",
    "    tempDF2 = pd.merge(tempS, tempDF2, left_index=True, right_index=True, how='left')\n",
    "    tempDF2 = tempDF2.drop(columns=['log_BaseBMI', 'Testing'])\n",
    "    tempDF1 = pd.merge(tempDF1['Base'+yvar_model], tempDF2,\n",
    "                       left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    #Obesity classification\n",
    "    for bmi in ['BMI', yvar_model]:\n",
    "        tempL = []\n",
    "        for value in tempDF1['Base'+bmi].tolist():\n",
    "            if np.isnan(value):\n",
    "                tempL.append('NotCalculated')\n",
    "            elif value < 18.5:\n",
    "                tempL.append('Underweight')\n",
    "            elif value < 25:\n",
    "                tempL.append('Normal')\n",
    "            elif value < 30:\n",
    "                tempL.append('Overweight')\n",
    "            elif value >= 30:\n",
    "                tempL.append('Obese')\n",
    "            else:#Just in case\n",
    "                tempL.append('Error?')\n",
    "        tempDF1['Base'+bmi+'_class'] = tempL\n",
    "    \n",
    "    #Check baseline summary\n",
    "    print(sex+' baseline summary:')\n",
    "    display(tempDF1.describe(include='all'))\n",
    "    for bmi in ['BMI', yvar_model]:\n",
    "        print('Base'+bmi+'_class:')\n",
    "        tempS1 = tempDF1['Base'+bmi+'_class'].value_counts()\n",
    "        tempDF2 = pd.DataFrame({'Count':tempS1, 'Percentage':tempS1/len(tempDF1)*100})\n",
    "        display(tempDF2)\n",
    "    \n",
    "    #Merge\n",
    "    tempDF = pd.merge(tempDF, tempDF1, left_on='public_client_id', right_index=True, how='left')\n",
    "    tempD[sex] = tempDF\n",
    "    display(tempDF)\n",
    "    print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "    print('')\n",
    "#Update\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save\n",
    "yvar_model = 'MetBMI'\n",
    "\n",
    "#Sex-stratified models\n",
    "tempDF = pd.concat([predictDF_F, predictDF_M], axis=0)\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220805_Multiomics-BMI-NatMed1stRevision_BMI-longitudinal-LASSO_'\n",
    "fileName = yvar_model+'-FemaleMale.tsv'\n",
    "tempDF.to_csv(fileDir+ipynbName+fileName, sep='\\t', index=True)\n",
    "\n",
    "#Sex-mixed model\n",
    "tempDF = predictDF_B\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220805_Multiomics-BMI-NatMed1stRevision_BMI-longitudinal-LASSO_'\n",
    "fileName = yvar_model+'-BothSex.tsv'\n",
    "tempDF.to_csv(fileDir+ipynbName+fileName, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-6. Check consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'Both sex':predictDF_B}\n",
    "yvar_model = 'MetBMI'\n",
    "axis_label = 'BMI [kg m'+r'$^{-2}$'+']'\n",
    "\n",
    "#Plot difference b/w sex-specific and sex-mixed models\n",
    "tempD2 = {'Female':'tab:red', 'Male':'tab:blue'}\n",
    "range_min = np.min([df[var].min() for df in tempD1.values() for var in [yvar_model]])\n",
    "range_max = np.max([df[var].max() for df in tempD1.values() for var in [yvar_model]])\n",
    "sns.set(style='ticks', font='Arial', context='talk')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(tempD2), figsize=(6.5, 3), sharex=True, sharey=True,\n",
    "                         gridspec_kw={'hspace':0.1, 'wspace':0.1})\n",
    "for ax_i, ax in enumerate(axes.flat):\n",
    "    sex = list(tempD2.keys())[ax_i]\n",
    "    #Prepare DF\n",
    "    tempS1 = tempD1[sex][yvar_model]\n",
    "    tempS1.name = 'Sex-specific'\n",
    "    tempS2 = tempD1['Both sex'][yvar_model]\n",
    "    tempS2.name = 'Sex-mixed'\n",
    "    tempDF = pd.merge(tempS1, tempS2, left_index=True, right_index=True, how='inner')\n",
    "    #Y=X as reference\n",
    "    ax.plot([range_min, range_max], [range_min, range_max], color='black', linestyle=(0, (1, 2)))\n",
    "    #Regplot\n",
    "    sns.regplot(data=tempDF, x='Sex-specific', y='Sex-mixed', color=tempD2[sex],\n",
    "                scatter=True, fit_reg=True, ci=95, truncate=False, marker='o',\n",
    "                scatter_kws={'alpha':0.2, 'edgecolor':'k', 's':30}, ax=ax)\n",
    "    if ax_i%len(tempD2)==0:\n",
    "        plt.setp(ax, xlabel='', ylabel='Sex-mixed b'+axis_label)\n",
    "    else:\n",
    "        plt.setp(ax, xlabel='', ylabel='')\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    ##Annotate Pearson's correlation\n",
    "    pearson_r, pval = stats.pearsonr(tempDF['Sex-specific'], tempDF['Sex-mixed'])\n",
    "    r_text = str(Decimal(str(pearson_r)).quantize(Decimal('0.001'), rounding=ROUND_HALF_UP))\n",
    "    if pval==1.0:\n",
    "        pval_text = '1.0'\n",
    "    elif pval==0.0:\n",
    "        pval_text = '0.0'\n",
    "    else:\n",
    "        pval_text = f'{Decimal(str(pval)):.3E}'#Take more digits because rounding is bad here\n",
    "        significand, exponent = pval_text.split(sep='E-')\n",
    "        significand = str(Decimal(significand).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP))\n",
    "        if significand=='10.0':\n",
    "            significand = '1.0'\n",
    "            exponent = str(int(exponent)-1)\n",
    "        if int(exponent)>2:\n",
    "            pval_text = significand+r'$\\times$'+'10'+r'$^{{-{0}}}$'.format(exponent)##Font is different in r'$ $'...\n",
    "        elif int(exponent)>0:\n",
    "            pval_text = '0.'+'0'*(int(exponent)-1)+significand.replace('.', '')\n",
    "        else:\n",
    "            pval_text = significand\n",
    "    text = 'Pearson\\'s '+r'$r$'+' = '+r_text+'\\n'+r'$P$'+' = '+pval_text\n",
    "    ax.annotate(text, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top',\n",
    "                multialignment='left', fontsize='x-small', color='k')\n",
    "    ##Facet label\n",
    "    ax.set_title(sex, {'fontsize':'medium'})\n",
    "    #Save position to generate facet and legend later\n",
    "    if ax_i ==0:\n",
    "        ax0_pos = ax.get_position().bounds\n",
    "    elif ax_i==1:\n",
    "        ax1_pos = ax.get_position().bounds\n",
    "sns.despine()\n",
    "fig.text(x=(ax0_pos[0]+(ax1_pos[0]+ax1_pos[2]))/2, y=ax0_pos[1]-ax0_pos[3]*0.2,#Minor manual adjustment\n",
    "         s='Sex-specific b'+axis_label, fontsize='medium',\n",
    "         verticalalignment='top', horizontalalignment='center', rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check consistency of the baseline predictions\n",
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'Both sex':predictDF_B}\n",
    "tempD2 = {'Female':'Female', 'Male':'Male', 'Both sex':'BothSex'}\n",
    "yvar_model = 'MetBMI'\n",
    "axis_label = 'BMI [kg m'+r'$^{-2}$'+']'\n",
    "\n",
    "tempD = {}\n",
    "for sex in tempD2.keys():\n",
    "    #Retrieve the baseline predictions\n",
    "    tempDF = tempD1[sex]\n",
    "    tempDF = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "    tempDF = tempDF.drop_duplicates('public_client_id', keep='first')\n",
    "    tempDF = tempDF.reset_index().set_index('public_client_id')\n",
    "    tempS1 = tempDF['Base'+yvar_model]\n",
    "    tempS1.name = 'Current'\n",
    "    \n",
    "    #Import the previous baseline prediction DF\n",
    "    fileDir = './ExportData/'\n",
    "    ipynbName = '220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_'\n",
    "    fileName = yvar_model+'-'+tempD2[sex]+'.tsv'\n",
    "    tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id':str})\n",
    "    tempDF = tempDF.set_index('public_client_id')\n",
    "    tempS2 = tempDF['Base'+yvar_model]\n",
    "    tempS2.name = 'Previous'\n",
    "    \n",
    "    tempDF = pd.merge(tempS1, tempS2, left_index=True, right_index=True, how='outer')\n",
    "    tempD[sex] = tempDF\n",
    "    \n",
    "    #Check exact values\n",
    "    print(sex)\n",
    "    print(' - Participant is consistent:', len(tempDF)==len(tempDF.dropna()))\n",
    "    tempDF1 = tempDF.loc[tempDF['Current']!=tempDF['Previous']]\n",
    "    print(' - Inconsistent baseline predictions:',\n",
    "          len(tempDF1), '(', len(tempDF1)/len(tempDF)*100, '[%])')\n",
    "    display(tempDF1)\n",
    "    \n",
    "    #Check obesity classification\n",
    "    for bbmi in ['Current', 'Previous']:\n",
    "        tempL = []\n",
    "        for value in tempDF[bbmi].tolist():\n",
    "            if np.isnan(value):\n",
    "                tempL.append('NotCalculated')\n",
    "            elif value < 18.5:\n",
    "                tempL.append('Underweight')\n",
    "            elif value < 25:\n",
    "                tempL.append('Normal')\n",
    "            elif value < 30:\n",
    "                tempL.append('Overweight')\n",
    "            elif value >= 30:\n",
    "                tempL.append('Obese')\n",
    "            else:#Just in case\n",
    "                tempL.append('Error?')\n",
    "        tempDF[bbmi+'_Base'+yvar_model+'_class'] = tempL\n",
    "        print(' - '+bbmi+'_Base'+yvar_model+'_class:')\n",
    "        tempS = tempDF[bbmi+'_Base'+yvar_model+'_class'].value_counts()\n",
    "        tempDF1 = pd.DataFrame({'Count':tempS, 'Percentage':tempS/len(tempDF)*100})\n",
    "        display(tempDF1)\n",
    "\n",
    "#Plot current vs. previous baseline predictions per model\n",
    "tempD2 = {'Female':'tab:red', 'Male':'tab:blue', 'Both sex':'tab:green'}\n",
    "range_min = np.min([df[var].min() for df in tempD.values() for var in ['Current', 'Previous']])\n",
    "range_max = np.max([df[var].max() for df in tempD.values() for var in ['Current', 'Previous']])\n",
    "sns.set(style='ticks', font='Arial', context='talk')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(tempD2), figsize=(10, 3), sharex=True, sharey=True,\n",
    "                         gridspec_kw={'hspace':0.1, 'wspace':0.1})\n",
    "for ax_i, ax in enumerate(axes.flat):\n",
    "    sex = list(tempD2.keys())[ax_i]\n",
    "    tempDF = tempD[sex]\n",
    "    #Y=X as reference\n",
    "    ax.plot([range_min, range_max], [range_min, range_max], color='black', linestyle=(0, (1, 2)))\n",
    "    #Regplot\n",
    "    sns.regplot(data=tempDF, x='Previous', y='Current', color=tempD2[sex],\n",
    "                scatter=True, fit_reg=True, ci=95, truncate=False, marker='o',\n",
    "                scatter_kws={'alpha':0.2, 'edgecolor':'k', 's':30}, ax=ax)\n",
    "    if ax_i%len(tempD2)==0:\n",
    "        plt.setp(ax, xlabel='', ylabel='Current b'+axis_label)\n",
    "    else:\n",
    "        plt.setp(ax, xlabel='', ylabel='')\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    ##Annotate Pearson's correlation\n",
    "    pearson_r, pval = stats.pearsonr(tempDF['Previous'], tempDF['Current'])\n",
    "    r_text = str(Decimal(str(pearson_r)).quantize(Decimal('0.001'), rounding=ROUND_HALF_UP))\n",
    "    if pval==1.0:\n",
    "        pval_text = '1.0'\n",
    "    elif pval==0.0:\n",
    "        pval_text = '0.0'\n",
    "    else:\n",
    "        pval_text = f'{Decimal(str(pval)):.3E}'#Take more digits because rounding is bad here\n",
    "        significand, exponent = pval_text.split(sep='E-')\n",
    "        significand = str(Decimal(significand).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP))\n",
    "        if significand=='10.0':\n",
    "            significand = '1.0'\n",
    "            exponent = str(int(exponent)-1)\n",
    "        if int(exponent)>2:\n",
    "            pval_text = significand+r'$\\times$'+'10'+r'$^{{-{0}}}$'.format(exponent)##Font is different in r'$ $'...\n",
    "        elif int(exponent)>0:\n",
    "            pval_text = '0.'+'0'*(int(exponent)-1)+significand.replace('.', '')\n",
    "        else:\n",
    "            pval_text = significand\n",
    "    text = 'Pearson\\'s '+r'$r$'+' = '+r_text+'\\n'+r'$P$'+' = '+pval_text\n",
    "    ax.annotate(text, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top',\n",
    "                multialignment='left', fontsize='x-small', color='k')\n",
    "    ##Facet label\n",
    "    ax.set_title(sex, {'fontsize':'medium'})\n",
    "    #Save position to generate facet and legend later\n",
    "    if ax_i ==0:\n",
    "        ax0_pos = ax.get_position().bounds\n",
    "    elif ax_i==2:\n",
    "        ax2_pos = ax.get_position().bounds\n",
    "sns.despine()\n",
    "fig.text(x=(ax0_pos[0]+(ax2_pos[0]+ax2_pos[2]))/2, y=ax0_pos[1]-ax0_pos[3]*0.2,#Minor manual adjustment\n",
    "         s='Previous b'+axis_label, fontsize='medium',\n",
    "         verticalalignment='top', horizontalalignment='center', rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> The inconsistent predictions were the same values (at least) until six decimal places, probably due to floating issues. In fact, bBMI class is surely consisistent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Proteomics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Prepare the cleaned omics dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Because the fitted models are used for predictions, the dependent variable (BMI) is not needed. (Of note, BMI was not necessarily available for the same point of omics measurements.) However, not only the time-series but also the baseline omics DF needs to be prepared for standardization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = 'protDF'\n",
    "\n",
    "#Import the cleaned baseline omics dataframes\n",
    "fileDir = '../210104_Biological-BMI-paper/ExportData/'\n",
    "ipynbName = '210104_Biological-BMI-paper_RF-imputation_'\n",
    "fileName = 'baseline-'+df_n+'-with-RF-imputation.tsv'\n",
    "tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id': str})\n",
    "tempDF = tempDF.set_index('public_client_id')\n",
    "print(df_n+' original shape:', tempDF.shape)\n",
    "\n",
    "#Drop BMI and covariates\n",
    "tempL = ['log_BaseBMI', 'Sex', 'BaseAge', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Race']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF)\n",
    "\n",
    "baseDF = tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = 'protDF'\n",
    "\n",
    "#Import the cleaned time-series omics dataframes\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220804_Multiomics-BMI-NatMed1stRevision_RF-imputation-ver2_'\n",
    "fileName = 'time-series-'+df_n+'-with-RF-imputation.tsv'\n",
    "tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id': str})\n",
    "tempDF = tempDF.set_index('KeyIndex')\n",
    "tempDF = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "print(df_n+' original shape:', tempDF.shape)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "\n",
    "#Drop BMI and covariates\n",
    "tempL = ['log_BaseBMI', 'Sex', 'BaseAge', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Race']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "\n",
    "tsDF = tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check consistency\n",
    "print('Baseline DF:')\n",
    "display(baseDF.describe())\n",
    "print('Baseline from the time-series DF:')\n",
    "tempDF = tsDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "tempDF = tempDF.drop_duplicates('public_client_id', keep='first')\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> Confirmed that the baseline measurements were consistent after the improved imputation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Standarization with the baseline distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "\n",
    "#Check just in case\n",
    "tempA1 = baseDF.columns.to_numpy()\n",
    "tempA2 = tsDF.drop(columns=tempL).columns.to_numpy()\n",
    "print('nVariables is consistent between baseline and time-series DFs:',\n",
    "      len(tempA1)==len(tempA2))\n",
    "print('Variable order is consistent between baseline and time-series DFs:',\n",
    "      (tempA1==tempA2).sum()==len(tempA1))\n",
    "\n",
    "tempD2 = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    tempL1 = tempDF.index.tolist()\n",
    "    #Prepare baseline DF\n",
    "    tempDF1 = baseDF.loc[tempL1]\n",
    "    #Compute the mean and std for Z-score transformation based on the baseline distribution\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    scaler.fit(tempDF1)#Column direction\n",
    "    #Z-score transformation of the baseline DF (just for confirmation)\n",
    "    tempA = scaler.transform(tempDF1)\n",
    "    tempDF1 = pd.DataFrame(data=tempA, index=tempDF1.index, columns=tempDF1.columns)\n",
    "    \n",
    "    #Prepare time-series DF\n",
    "    tempDF2 = tsDF.loc[tsDF['public_client_id'].isin(tempL1)]\n",
    "    tempDF = tempDF2.drop(columns=tempL)\n",
    "    #Z-score transformation of the time-series DF with the baseline distribution\n",
    "    tempA = scaler.transform(tempDF)\n",
    "    tempDF = pd.DataFrame(data=tempA, index=tempDF.index, columns=tempDF.columns)\n",
    "    #Recover the time-series metadata\n",
    "    tempDF2 = tempDF2[tempL]\n",
    "    tempDF2 = pd.merge(tempDF2, tempDF, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    print(sex)\n",
    "    display(tempDF2)\n",
    "    tempD2[sex] = tempDF2\n",
    "    \n",
    "    #Confirmation\n",
    "    tempD = {'Baseline DF':tempDF1, 'Time-series DF':tempDF2}\n",
    "    for df_n in tempD.keys():\n",
    "        tempDF = tempD[df_n]\n",
    "        print(' - '+df_n, tempDF.shape)\n",
    "        if df_n=='Time-series DF':\n",
    "            print('    -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "            tempDF = tempDF.drop(columns=tempL)\n",
    "        display(tempDF.describe())\n",
    "        sns.set(style='ticks', font='Arial', context='notebook')\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        for col_i in range(3):\n",
    "            sns.distplot(tempDF.iloc[:, col_i], label=tempDF.columns[col_i])\n",
    "        sns.despine()\n",
    "        plt.xlabel(r'$Z$'+'-score')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend(bbox_to_anchor=(1, 0.5), loc='center left', borderaxespad=1)\n",
    "        plt.show()\n",
    "    print('')\n",
    "\n",
    "tsDF_F = tempD2['Female']\n",
    "tsDF_M = tempD2['Male']\n",
    "tsDF_B = tempD2['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> Confirmed that the baseline summary was completely same with the before (the baseline LASSO modeling).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Import the fitted LASSO models with the baseline measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar_model = 'ProtBMI'\n",
    "tempD = {}\n",
    "for sex in ['Female', 'Male', 'BothSex']:\n",
    "    #Import the LASSO beta-coefficients (including intercept)\n",
    "    fileDir = './ExportData/'\n",
    "    ipynbName = '220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_'\n",
    "    fileName = yvar_model+'-'+sex+'-LASSObcoefs.tsv'\n",
    "    tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t').set_index('Variable')\n",
    "    #Drop summary columns\n",
    "    tempL = ['Mean', 'SD', 'nZeros']\n",
    "    tempDF = tempDF.drop(columns=tempL)\n",
    "    tempD[sex] = tempDF\n",
    "    \n",
    "    #Check\n",
    "    print(sex+':')\n",
    "    print(' - Variables (without intercept):', len(tempDF)-1)\n",
    "    display(tempDF)\n",
    "    print('')\n",
    "\n",
    "modelDF_F = tempD['Female']\n",
    "modelDF_M = tempD['Male']\n",
    "modelDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4. Calculate predictions using the fitted models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> According to LassoCV source, the self.predict(X) method calls self._decision_function(X) method, which further returns “safe_sparsedot(X, self.coef.T, denseoutput=True) + self.intercept\". In this case, safe_sparse_dot() simply corresponds to a dot product. Hence, manual calculation from beta-coefficients and intercept is impremented here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':tsDF_F, 'Male':tsDF_M, 'BothSex':tsDF_B}\n",
    "tempD2 = {'Female':modelDF_F, 'Male':modelDF_M, 'BothSex':modelDF_B}\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    tempDF1 = tempDF.drop(columns=tempL)\n",
    "    tempDF2 = tempD2[sex]\n",
    "    \n",
    "    #Add dummy intercept variable to data DF\n",
    "    tempDF1['Intercept'] = 1.0\n",
    "    \n",
    "    #Check just in case\n",
    "    tempA1 = tempDF1.columns.to_numpy()\n",
    "    tempA2 = tempDF2.index.to_numpy()\n",
    "    print(sex)\n",
    "    print(' - nVariables is consistent between data and model DFs:',\n",
    "          len(tempA1)==len(tempA2))\n",
    "    print(' - Variable order is consistent between data and model DFs:',\n",
    "          (tempA1==tempA2).sum()==len(tempA1))\n",
    "    \n",
    "    #Calculate prediction\n",
    "    tempA = np.dot(tempDF1, tempDF2)\n",
    "    tempDF1 = pd.DataFrame(tempA, index=tempDF1.index, columns=tempDF2.columns)\n",
    "    \n",
    "    #Recover the time-series metadata\n",
    "    tempDF = tempDF[tempL]\n",
    "    tempDF = pd.merge(tempDF, tempDF1, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    tempD[sex] = tempDF\n",
    "    display(tempDF)\n",
    "    print('')\n",
    "\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To obtain one single prediction for each participant and each time point, the calculated predictions from each model can be averaged.  \n",
    "> ***–> However, in addition to the overfitting problem for the baseline predictions, there is a potential risk of data leakage even for the longitudinal predictions.***  \n",
    "> –> In this version, one single prediction for each participant and each time point is selected with the prediction from the model for which the participant was included in the baseline testing (hold-out) set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "tempD2 = {'Female':predictDF_F, 'Male':predictDF_M, 'BothSex':predictDF_B}\n",
    "yvar_model = 'ProtBMI'\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    #Retrieve the predictions for the testing (hold-out) set\n",
    "    tempDF = tempD1[sex]\n",
    "    tempS = tempDF['Testing']\n",
    "    tempDF = tempD2[sex]\n",
    "    tempDF = pd.merge(tempDF, tempS, left_on='public_client_id', right_index=True, how='left')\n",
    "    tempL = []\n",
    "    for row_i in range(len(tempDF)):\n",
    "        model_n = tempDF['Testing'].iloc[row_i]\n",
    "        tempL.append(tempDF[model_n].iloc[row_i])\n",
    "    tempDF['log_'+yvar_model] = tempL\n",
    "    \n",
    "    #Drop the temporal prediction columns\n",
    "    tempDF = tempDF.loc[:, ~tempDF.columns.str.contains('Model_')]\n",
    "    \n",
    "    #Convert to original scale\n",
    "    tempDF[yvar_model] = np.e**tempDF['log_'+yvar_model]\n",
    "    \n",
    "    tempD[sex] = tempDF\n",
    "    print(sex)\n",
    "    display(tempDF)\n",
    "    print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "    print('')\n",
    "#Update\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-5. Clean and save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the baseline info\n",
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'BothSex':predictDF_B}\n",
    "tempD2 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "yvar_model = 'ProtBMI'\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    \n",
    "    #Retrieve the baseline predictions\n",
    "    tempDF1 = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "    tempDF1 = tempDF1.drop_duplicates('public_client_id', keep='first')\n",
    "    tempDF1 = tempDF1.reset_index().set_index('public_client_id')\n",
    "    tempDF1 = tempDF1.rename(columns={yvar_model:'Base'+yvar_model})\n",
    "    \n",
    "    #Add baseline BMI and covariate info\n",
    "    tempDF2 = tempD2[sex]\n",
    "    ##Replace the log-scaled BMI with the original scaled\n",
    "    tempS = np.e**tempDF2['log_BaseBMI']\n",
    "    tempS.name = 'BaseBMI'\n",
    "    tempDF2 = pd.merge(tempS, tempDF2, left_index=True, right_index=True, how='left')\n",
    "    tempDF2 = tempDF2.drop(columns=['log_BaseBMI', 'Testing'])\n",
    "    tempDF1 = pd.merge(tempDF1['Base'+yvar_model], tempDF2,\n",
    "                       left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    #Obesity classification\n",
    "    for bmi in ['BMI', yvar_model]:\n",
    "        tempL = []\n",
    "        for value in tempDF1['Base'+bmi].tolist():\n",
    "            if np.isnan(value):\n",
    "                tempL.append('NotCalculated')\n",
    "            elif value < 18.5:\n",
    "                tempL.append('Underweight')\n",
    "            elif value < 25:\n",
    "                tempL.append('Normal')\n",
    "            elif value < 30:\n",
    "                tempL.append('Overweight')\n",
    "            elif value >= 30:\n",
    "                tempL.append('Obese')\n",
    "            else:#Just in case\n",
    "                tempL.append('Error?')\n",
    "        tempDF1['Base'+bmi+'_class'] = tempL\n",
    "    \n",
    "    #Check baseline summary\n",
    "    print(sex+' baseline summary:')\n",
    "    display(tempDF1.describe(include='all'))\n",
    "    for bmi in ['BMI', yvar_model]:\n",
    "        print('Base'+bmi+'_class:')\n",
    "        tempS1 = tempDF1['Base'+bmi+'_class'].value_counts()\n",
    "        tempDF2 = pd.DataFrame({'Count':tempS1, 'Percentage':tempS1/len(tempDF1)*100})\n",
    "        display(tempDF2)\n",
    "    \n",
    "    #Merge\n",
    "    tempDF = pd.merge(tempDF, tempDF1, left_on='public_client_id', right_index=True, how='left')\n",
    "    tempD[sex] = tempDF\n",
    "    display(tempDF)\n",
    "    print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "    print('')\n",
    "#Update\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save\n",
    "yvar_model = 'ProtBMI'\n",
    "\n",
    "#Sex-stratified models\n",
    "tempDF = pd.concat([predictDF_F, predictDF_M], axis=0)\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220805_Multiomics-BMI-NatMed1stRevision_BMI-longitudinal-LASSO_'\n",
    "fileName = yvar_model+'-FemaleMale.tsv'\n",
    "tempDF.to_csv(fileDir+ipynbName+fileName, sep='\\t', index=True)\n",
    "\n",
    "#Sex-mixed model\n",
    "tempDF = predictDF_B\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220805_Multiomics-BMI-NatMed1stRevision_BMI-longitudinal-LASSO_'\n",
    "fileName = yvar_model+'-BothSex.tsv'\n",
    "tempDF.to_csv(fileDir+ipynbName+fileName, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-6. Check consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'Both sex':predictDF_B}\n",
    "yvar_model = 'ProtBMI'\n",
    "axis_label = 'BMI [kg m'+r'$^{-2}$'+']'\n",
    "\n",
    "#Plot difference b/w sex-specific and sex-mixed models\n",
    "tempD2 = {'Female':'tab:red', 'Male':'tab:blue'}\n",
    "range_min = np.min([df[var].min() for df in tempD1.values() for var in [yvar_model]])\n",
    "range_max = np.max([df[var].max() for df in tempD1.values() for var in [yvar_model]])\n",
    "sns.set(style='ticks', font='Arial', context='talk')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(tempD2), figsize=(6.5, 3), sharex=True, sharey=True,\n",
    "                         gridspec_kw={'hspace':0.1, 'wspace':0.1})\n",
    "for ax_i, ax in enumerate(axes.flat):\n",
    "    sex = list(tempD2.keys())[ax_i]\n",
    "    #Prepare DF\n",
    "    tempS1 = tempD1[sex][yvar_model]\n",
    "    tempS1.name = 'Sex-specific'\n",
    "    tempS2 = tempD1['Both sex'][yvar_model]\n",
    "    tempS2.name = 'Sex-mixed'\n",
    "    tempDF = pd.merge(tempS1, tempS2, left_index=True, right_index=True, how='inner')\n",
    "    #Y=X as reference\n",
    "    ax.plot([range_min, range_max], [range_min, range_max], color='black', linestyle=(0, (1, 2)))\n",
    "    #Regplot\n",
    "    sns.regplot(data=tempDF, x='Sex-specific', y='Sex-mixed', color=tempD2[sex],\n",
    "                scatter=True, fit_reg=True, ci=95, truncate=False, marker='o',\n",
    "                scatter_kws={'alpha':0.2, 'edgecolor':'k', 's':30}, ax=ax)\n",
    "    if ax_i%len(tempD2)==0:\n",
    "        plt.setp(ax, xlabel='', ylabel='Sex-mixed b'+axis_label)\n",
    "    else:\n",
    "        plt.setp(ax, xlabel='', ylabel='')\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    ##Annotate Pearson's correlation\n",
    "    pearson_r, pval = stats.pearsonr(tempDF['Sex-specific'], tempDF['Sex-mixed'])\n",
    "    r_text = str(Decimal(str(pearson_r)).quantize(Decimal('0.001'), rounding=ROUND_HALF_UP))\n",
    "    if pval==1.0:\n",
    "        pval_text = '1.0'\n",
    "    elif pval==0.0:\n",
    "        pval_text = '0.0'\n",
    "    else:\n",
    "        pval_text = f'{Decimal(str(pval)):.3E}'#Take more digits because rounding is bad here\n",
    "        significand, exponent = pval_text.split(sep='E-')\n",
    "        significand = str(Decimal(significand).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP))\n",
    "        if significand=='10.0':\n",
    "            significand = '1.0'\n",
    "            exponent = str(int(exponent)-1)\n",
    "        if int(exponent)>2:\n",
    "            pval_text = significand+r'$\\times$'+'10'+r'$^{{-{0}}}$'.format(exponent)##Font is different in r'$ $'...\n",
    "        elif int(exponent)>0:\n",
    "            pval_text = '0.'+'0'*(int(exponent)-1)+significand.replace('.', '')\n",
    "        else:\n",
    "            pval_text = significand\n",
    "    text = 'Pearson\\'s '+r'$r$'+' = '+r_text+'\\n'+r'$P$'+' = '+pval_text\n",
    "    ax.annotate(text, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top',\n",
    "                multialignment='left', fontsize='x-small', color='k')\n",
    "    ##Facet label\n",
    "    ax.set_title(sex, {'fontsize':'medium'})\n",
    "    #Save position to generate facet and legend later\n",
    "    if ax_i ==0:\n",
    "        ax0_pos = ax.get_position().bounds\n",
    "    elif ax_i==1:\n",
    "        ax1_pos = ax.get_position().bounds\n",
    "sns.despine()\n",
    "fig.text(x=(ax0_pos[0]+(ax1_pos[0]+ax1_pos[2]))/2, y=ax0_pos[1]-ax0_pos[3]*0.2,#Minor manual adjustment\n",
    "         s='Sex-specific b'+axis_label, fontsize='medium',\n",
    "         verticalalignment='top', horizontalalignment='center', rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check consistency of the baseline predictions\n",
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'Both sex':predictDF_B}\n",
    "tempD2 = {'Female':'Female', 'Male':'Male', 'Both sex':'BothSex'}\n",
    "yvar_model = 'ProtBMI'\n",
    "axis_label = 'BMI [kg m'+r'$^{-2}$'+']'\n",
    "\n",
    "tempD = {}\n",
    "for sex in tempD2.keys():\n",
    "    #Retrieve the baseline predictions\n",
    "    tempDF = tempD1[sex]\n",
    "    tempDF = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "    tempDF = tempDF.drop_duplicates('public_client_id', keep='first')\n",
    "    tempDF = tempDF.reset_index().set_index('public_client_id')\n",
    "    tempS1 = tempDF['Base'+yvar_model]\n",
    "    tempS1.name = 'Current'\n",
    "    \n",
    "    #Import the previous baseline prediction DF\n",
    "    fileDir = './ExportData/'\n",
    "    ipynbName = '220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_'\n",
    "    fileName = yvar_model+'-'+tempD2[sex]+'.tsv'\n",
    "    tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id':str})\n",
    "    tempDF = tempDF.set_index('public_client_id')\n",
    "    tempS2 = tempDF['Base'+yvar_model]\n",
    "    tempS2.name = 'Previous'\n",
    "    \n",
    "    tempDF = pd.merge(tempS1, tempS2, left_index=True, right_index=True, how='outer')\n",
    "    tempD[sex] = tempDF\n",
    "    \n",
    "    #Check exact values\n",
    "    print(sex)\n",
    "    print(' - Participant is consistent:', len(tempDF)==len(tempDF.dropna()))\n",
    "    tempDF1 = tempDF.loc[tempDF['Current']!=tempDF['Previous']]\n",
    "    print(' - Inconsistent baseline predictions:',\n",
    "          len(tempDF1), '(', len(tempDF1)/len(tempDF)*100, '[%])')\n",
    "    display(tempDF1)\n",
    "    \n",
    "    #Check obesity classification\n",
    "    for bbmi in ['Current', 'Previous']:\n",
    "        tempL = []\n",
    "        for value in tempDF[bbmi].tolist():\n",
    "            if np.isnan(value):\n",
    "                tempL.append('NotCalculated')\n",
    "            elif value < 18.5:\n",
    "                tempL.append('Underweight')\n",
    "            elif value < 25:\n",
    "                tempL.append('Normal')\n",
    "            elif value < 30:\n",
    "                tempL.append('Overweight')\n",
    "            elif value >= 30:\n",
    "                tempL.append('Obese')\n",
    "            else:#Just in case\n",
    "                tempL.append('Error?')\n",
    "        tempDF[bbmi+'_Base'+yvar_model+'_class'] = tempL\n",
    "        print(' - '+bbmi+'_Base'+yvar_model+'_class:')\n",
    "        tempS = tempDF[bbmi+'_Base'+yvar_model+'_class'].value_counts()\n",
    "        tempDF1 = pd.DataFrame({'Count':tempS, 'Percentage':tempS/len(tempDF)*100})\n",
    "        display(tempDF1)\n",
    "\n",
    "#Plot current vs. previous baseline predictions per model\n",
    "tempD2 = {'Female':'tab:red', 'Male':'tab:blue', 'Both sex':'tab:green'}\n",
    "range_min = np.min([df[var].min() for df in tempD.values() for var in ['Current', 'Previous']])\n",
    "range_max = np.max([df[var].max() for df in tempD.values() for var in ['Current', 'Previous']])\n",
    "sns.set(style='ticks', font='Arial', context='talk')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(tempD2), figsize=(10, 3), sharex=True, sharey=True,\n",
    "                         gridspec_kw={'hspace':0.1, 'wspace':0.1})\n",
    "for ax_i, ax in enumerate(axes.flat):\n",
    "    sex = list(tempD2.keys())[ax_i]\n",
    "    tempDF = tempD[sex]\n",
    "    #Y=X as reference\n",
    "    ax.plot([range_min, range_max], [range_min, range_max], color='black', linestyle=(0, (1, 2)))\n",
    "    #Regplot\n",
    "    sns.regplot(data=tempDF, x='Previous', y='Current', color=tempD2[sex],\n",
    "                scatter=True, fit_reg=True, ci=95, truncate=False, marker='o',\n",
    "                scatter_kws={'alpha':0.2, 'edgecolor':'k', 's':30}, ax=ax)\n",
    "    if ax_i%len(tempD2)==0:\n",
    "        plt.setp(ax, xlabel='', ylabel='Current b'+axis_label)\n",
    "    else:\n",
    "        plt.setp(ax, xlabel='', ylabel='')\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    ##Annotate Pearson's correlation\n",
    "    pearson_r, pval = stats.pearsonr(tempDF['Previous'], tempDF['Current'])\n",
    "    r_text = str(Decimal(str(pearson_r)).quantize(Decimal('0.001'), rounding=ROUND_HALF_UP))\n",
    "    if pval==1.0:\n",
    "        pval_text = '1.0'\n",
    "    elif pval==0.0:\n",
    "        pval_text = '0.0'\n",
    "    else:\n",
    "        pval_text = f'{Decimal(str(pval)):.3E}'#Take more digits because rounding is bad here\n",
    "        significand, exponent = pval_text.split(sep='E-')\n",
    "        significand = str(Decimal(significand).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP))\n",
    "        if significand=='10.0':\n",
    "            significand = '1.0'\n",
    "            exponent = str(int(exponent)-1)\n",
    "        if int(exponent)>2:\n",
    "            pval_text = significand+r'$\\times$'+'10'+r'$^{{-{0}}}$'.format(exponent)##Font is different in r'$ $'...\n",
    "        elif int(exponent)>0:\n",
    "            pval_text = '0.'+'0'*(int(exponent)-1)+significand.replace('.', '')\n",
    "        else:\n",
    "            pval_text = significand\n",
    "    text = 'Pearson\\'s '+r'$r$'+' = '+r_text+'\\n'+r'$P$'+' = '+pval_text\n",
    "    ax.annotate(text, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top',\n",
    "                multialignment='left', fontsize='x-small', color='k')\n",
    "    ##Facet label\n",
    "    ax.set_title(sex, {'fontsize':'medium'})\n",
    "    #Save position to generate facet and legend later\n",
    "    if ax_i ==0:\n",
    "        ax0_pos = ax.get_position().bounds\n",
    "    elif ax_i==2:\n",
    "        ax2_pos = ax.get_position().bounds\n",
    "sns.despine()\n",
    "fig.text(x=(ax0_pos[0]+(ax2_pos[0]+ax2_pos[2]))/2, y=ax0_pos[1]-ax0_pos[3]*0.2,#Minor manual adjustment\n",
    "         s='Previous b'+axis_label, fontsize='medium',\n",
    "         verticalalignment='top', horizontalalignment='center', rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> The inconsistent predictions were the same values (at least) until six decimal places, probably due to floating issues. In fact, bBMI class is surely consisistent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clinical labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Prepare the cleaned omics dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Because the fitted models are used for predictions, the dependent variable (BMI) is not needed. (Of note, BMI was not necessarily available for the same point of omics measurements.) However, not only the time-series but also the baseline omics DF needs to be prepared for standardization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = 'chemDF'\n",
    "\n",
    "#Import the cleaned baseline omics dataframes\n",
    "fileDir = '../210104_Biological-BMI-paper/ExportData/'\n",
    "ipynbName = '210104_Biological-BMI-paper_RF-imputation_'\n",
    "fileName = 'baseline-'+df_n+'-with-RF-imputation.tsv'\n",
    "tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id': str})\n",
    "tempDF = tempDF.set_index('public_client_id')\n",
    "print(df_n+' original shape:', tempDF.shape)\n",
    "\n",
    "#Drop BMI and covariates\n",
    "tempL = ['log_BaseBMI', 'Sex', 'BaseAge', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Race']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF)\n",
    "\n",
    "baseDF = tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = 'chemDF'\n",
    "\n",
    "#Import the cleaned time-series omics dataframes\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220804_Multiomics-BMI-NatMed1stRevision_RF-imputation-ver2_'\n",
    "fileName = 'time-series-'+df_n+'-with-RF-imputation.tsv'\n",
    "tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id': str})\n",
    "tempDF = tempDF.set_index('KeyIndex')\n",
    "tempDF = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "print(df_n+' original shape:', tempDF.shape)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "\n",
    "#Drop BMI and covariates\n",
    "tempL = ['log_BaseBMI', 'Sex', 'BaseAge', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Race']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "\n",
    "tsDF = tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check consistency\n",
    "print('Baseline DF:')\n",
    "display(baseDF.describe())\n",
    "print('Baseline from the time-series DF:')\n",
    "tempDF = tsDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "tempDF = tempDF.drop_duplicates('public_client_id', keep='first')\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> Confirmed that the baseline measurements were consistent after the improved imputation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Standarization with the baseline distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "\n",
    "#Check just in case\n",
    "tempA1 = baseDF.columns.to_numpy()\n",
    "tempA2 = tsDF.drop(columns=tempL).columns.to_numpy()\n",
    "print('nVariables is consistent between baseline and time-series DFs:',\n",
    "      len(tempA1)==len(tempA2))\n",
    "print('Variable order is consistent between baseline and time-series DFs:',\n",
    "      (tempA1==tempA2).sum()==len(tempA1))\n",
    "\n",
    "tempD2 = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    tempL1 = tempDF.index.tolist()\n",
    "    #Prepare baseline DF\n",
    "    tempDF1 = baseDF.loc[tempL1]\n",
    "    #Compute the mean and std for Z-score transformation based on the baseline distribution\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    scaler.fit(tempDF1)#Column direction\n",
    "    #Z-score transformation of the baseline DF (just for confirmation)\n",
    "    tempA = scaler.transform(tempDF1)\n",
    "    tempDF1 = pd.DataFrame(data=tempA, index=tempDF1.index, columns=tempDF1.columns)\n",
    "    \n",
    "    #Prepare time-series DF\n",
    "    tempDF2 = tsDF.loc[tsDF['public_client_id'].isin(tempL1)]\n",
    "    tempDF = tempDF2.drop(columns=tempL)\n",
    "    #Z-score transformation of the time-series DF with the baseline distribution\n",
    "    tempA = scaler.transform(tempDF)\n",
    "    tempDF = pd.DataFrame(data=tempA, index=tempDF.index, columns=tempDF.columns)\n",
    "    #Recover the time-series metadata\n",
    "    tempDF2 = tempDF2[tempL]\n",
    "    tempDF2 = pd.merge(tempDF2, tempDF, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    print(sex)\n",
    "    display(tempDF2)\n",
    "    tempD2[sex] = tempDF2\n",
    "    \n",
    "    #Confirmation\n",
    "    tempD = {'Baseline DF':tempDF1, 'Time-series DF':tempDF2}\n",
    "    for df_n in tempD.keys():\n",
    "        tempDF = tempD[df_n]\n",
    "        print(' - '+df_n, tempDF.shape)\n",
    "        if df_n=='Time-series DF':\n",
    "            print('    -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "            tempDF = tempDF.drop(columns=tempL)\n",
    "        display(tempDF.describe())\n",
    "        sns.set(style='ticks', font='Arial', context='notebook')\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        for col_i in range(3):\n",
    "            sns.distplot(tempDF.iloc[:, col_i], label=tempDF.columns[col_i])\n",
    "        sns.despine()\n",
    "        plt.xlabel(r'$Z$'+'-score')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend(bbox_to_anchor=(1, 0.5), loc='center left', borderaxespad=1)\n",
    "        plt.show()\n",
    "    print('')\n",
    "\n",
    "tsDF_F = tempD2['Female']\n",
    "tsDF_M = tempD2['Male']\n",
    "tsDF_B = tempD2['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> Confirmed that the baseline summary was completely same with the before (the baseline LASSO modeling).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. Import the fitted LASSO models with the baseline measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar_model = 'ChemBMI'\n",
    "tempD = {}\n",
    "for sex in ['Female', 'Male', 'BothSex']:\n",
    "    #Import the LASSO beta-coefficients (including intercept)\n",
    "    fileDir = './ExportData/'\n",
    "    ipynbName = '220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_'\n",
    "    fileName = yvar_model+'-'+sex+'-LASSObcoefs.tsv'\n",
    "    tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t').set_index('Variable')\n",
    "    #Drop summary columns\n",
    "    tempL = ['Mean', 'SD', 'nZeros']\n",
    "    tempDF = tempDF.drop(columns=tempL)\n",
    "    tempD[sex] = tempDF\n",
    "    \n",
    "    #Check\n",
    "    print(sex+':')\n",
    "    print(' - Variables (without intercept):', len(tempDF)-1)\n",
    "    display(tempDF)\n",
    "    print('')\n",
    "\n",
    "modelDF_F = tempD['Female']\n",
    "modelDF_M = tempD['Male']\n",
    "modelDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4. Calculate predictions using the fitted models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> According to LassoCV source, the self.predict(X) method calls self._decision_function(X) method, which further returns “safe_sparsedot(X, self.coef.T, denseoutput=True) + self.intercept\". In this case, safe_sparse_dot() simply corresponds to a dot product. Hence, manual calculation from beta-coefficients and intercept is impremented here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':tsDF_F, 'Male':tsDF_M, 'BothSex':tsDF_B}\n",
    "tempD2 = {'Female':modelDF_F, 'Male':modelDF_M, 'BothSex':modelDF_B}\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    tempDF1 = tempDF.drop(columns=tempL)\n",
    "    tempDF2 = tempD2[sex]\n",
    "    \n",
    "    #Add dummy intercept variable to data DF\n",
    "    tempDF1['Intercept'] = 1.0\n",
    "    \n",
    "    #Check just in case\n",
    "    tempA1 = tempDF1.columns.to_numpy()\n",
    "    tempA2 = tempDF2.index.to_numpy()\n",
    "    print(sex)\n",
    "    print(' - nVariables is consistent between data and model DFs:',\n",
    "          len(tempA1)==len(tempA2))\n",
    "    print(' - Variable order is consistent between data and model DFs:',\n",
    "          (tempA1==tempA2).sum()==len(tempA1))\n",
    "    \n",
    "    #Calculate prediction\n",
    "    tempA = np.dot(tempDF1, tempDF2)\n",
    "    tempDF1 = pd.DataFrame(tempA, index=tempDF1.index, columns=tempDF2.columns)\n",
    "    \n",
    "    #Recover the time-series metadata\n",
    "    tempDF = tempDF[tempL]\n",
    "    tempDF = pd.merge(tempDF, tempDF1, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    tempD[sex] = tempDF\n",
    "    display(tempDF)\n",
    "    print('')\n",
    "\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To obtain one single prediction for each participant and each time point, the calculated predictions from each model can be averaged.  \n",
    "> ***–> However, in addition to the overfitting problem for the baseline predictions, there is a potential risk of data leakage even for the longitudinal predictions.***  \n",
    "> –> In this version, one single prediction for each participant and each time point is selected with the prediction from the model for which the participant was included in the baseline testing (hold-out) set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "tempD2 = {'Female':predictDF_F, 'Male':predictDF_M, 'BothSex':predictDF_B}\n",
    "yvar_model = 'ChemBMI'\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    #Retrieve the predictions for the testing (hold-out) set\n",
    "    tempDF = tempD1[sex]\n",
    "    tempS = tempDF['Testing']\n",
    "    tempDF = tempD2[sex]\n",
    "    tempDF = pd.merge(tempDF, tempS, left_on='public_client_id', right_index=True, how='left')\n",
    "    tempL = []\n",
    "    for row_i in range(len(tempDF)):\n",
    "        model_n = tempDF['Testing'].iloc[row_i]\n",
    "        tempL.append(tempDF[model_n].iloc[row_i])\n",
    "    tempDF['log_'+yvar_model] = tempL\n",
    "    \n",
    "    #Drop the temporal prediction columns\n",
    "    tempDF = tempDF.loc[:, ~tempDF.columns.str.contains('Model_')]\n",
    "    \n",
    "    #Convert to original scale\n",
    "    tempDF[yvar_model] = np.e**tempDF['log_'+yvar_model]\n",
    "    \n",
    "    tempD[sex] = tempDF\n",
    "    print(sex)\n",
    "    display(tempDF)\n",
    "    print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "    print('')\n",
    "#Update\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-5. Clean and save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the baseline info\n",
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'BothSex':predictDF_B}\n",
    "tempD2 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "yvar_model = 'ChemBMI'\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    \n",
    "    #Retrieve the baseline predictions\n",
    "    tempDF1 = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "    tempDF1 = tempDF1.drop_duplicates('public_client_id', keep='first')\n",
    "    tempDF1 = tempDF1.reset_index().set_index('public_client_id')\n",
    "    tempDF1 = tempDF1.rename(columns={yvar_model:'Base'+yvar_model})\n",
    "    \n",
    "    #Add baseline BMI and covariate info\n",
    "    tempDF2 = tempD2[sex]\n",
    "    ##Replace the log-scaled BMI with the original scaled\n",
    "    tempS = np.e**tempDF2['log_BaseBMI']\n",
    "    tempS.name = 'BaseBMI'\n",
    "    tempDF2 = pd.merge(tempS, tempDF2, left_index=True, right_index=True, how='left')\n",
    "    tempDF2 = tempDF2.drop(columns=['log_BaseBMI', 'Testing'])\n",
    "    tempDF1 = pd.merge(tempDF1['Base'+yvar_model], tempDF2,\n",
    "                       left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    #Obesity classification\n",
    "    for bmi in ['BMI', yvar_model]:\n",
    "        tempL = []\n",
    "        for value in tempDF1['Base'+bmi].tolist():\n",
    "            if np.isnan(value):\n",
    "                tempL.append('NotCalculated')\n",
    "            elif value < 18.5:\n",
    "                tempL.append('Underweight')\n",
    "            elif value < 25:\n",
    "                tempL.append('Normal')\n",
    "            elif value < 30:\n",
    "                tempL.append('Overweight')\n",
    "            elif value >= 30:\n",
    "                tempL.append('Obese')\n",
    "            else:#Just in case\n",
    "                tempL.append('Error?')\n",
    "        tempDF1['Base'+bmi+'_class'] = tempL\n",
    "    \n",
    "    #Check baseline summary\n",
    "    print(sex+' baseline summary:')\n",
    "    display(tempDF1.describe(include='all'))\n",
    "    for bmi in ['BMI', yvar_model]:\n",
    "        print('Base'+bmi+'_class:')\n",
    "        tempS1 = tempDF1['Base'+bmi+'_class'].value_counts()\n",
    "        tempDF2 = pd.DataFrame({'Count':tempS1, 'Percentage':tempS1/len(tempDF1)*100})\n",
    "        display(tempDF2)\n",
    "    \n",
    "    #Merge\n",
    "    tempDF = pd.merge(tempDF, tempDF1, left_on='public_client_id', right_index=True, how='left')\n",
    "    tempD[sex] = tempDF\n",
    "    display(tempDF)\n",
    "    print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "    print('')\n",
    "#Update\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save\n",
    "yvar_model = 'ChemBMI'\n",
    "\n",
    "#Sex-stratified models\n",
    "tempDF = pd.concat([predictDF_F, predictDF_M], axis=0)\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220805_Multiomics-BMI-NatMed1stRevision_BMI-longitudinal-LASSO_'\n",
    "fileName = yvar_model+'-FemaleMale.tsv'\n",
    "tempDF.to_csv(fileDir+ipynbName+fileName, sep='\\t', index=True)\n",
    "\n",
    "#Sex-mixed model\n",
    "tempDF = predictDF_B\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220805_Multiomics-BMI-NatMed1stRevision_BMI-longitudinal-LASSO_'\n",
    "fileName = yvar_model+'-BothSex.tsv'\n",
    "tempDF.to_csv(fileDir+ipynbName+fileName, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-6. Check consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'Both sex':predictDF_B}\n",
    "yvar_model = 'ChemBMI'\n",
    "axis_label = 'BMI [kg m'+r'$^{-2}$'+']'\n",
    "\n",
    "#Plot difference b/w sex-specific and sex-mixed models\n",
    "tempD2 = {'Female':'tab:red', 'Male':'tab:blue'}\n",
    "range_min = np.min([df[var].min() for df in tempD1.values() for var in [yvar_model]])\n",
    "range_max = np.max([df[var].max() for df in tempD1.values() for var in [yvar_model]])\n",
    "sns.set(style='ticks', font='Arial', context='talk')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(tempD2), figsize=(6.5, 3), sharex=True, sharey=True,\n",
    "                         gridspec_kw={'hspace':0.1, 'wspace':0.1})\n",
    "for ax_i, ax in enumerate(axes.flat):\n",
    "    sex = list(tempD2.keys())[ax_i]\n",
    "    #Prepare DF\n",
    "    tempS1 = tempD1[sex][yvar_model]\n",
    "    tempS1.name = 'Sex-specific'\n",
    "    tempS2 = tempD1['Both sex'][yvar_model]\n",
    "    tempS2.name = 'Sex-mixed'\n",
    "    tempDF = pd.merge(tempS1, tempS2, left_index=True, right_index=True, how='inner')\n",
    "    #Y=X as reference\n",
    "    ax.plot([range_min, range_max], [range_min, range_max], color='black', linestyle=(0, (1, 2)))\n",
    "    #Regplot\n",
    "    sns.regplot(data=tempDF, x='Sex-specific', y='Sex-mixed', color=tempD2[sex],\n",
    "                scatter=True, fit_reg=True, ci=95, truncate=False, marker='o',\n",
    "                scatter_kws={'alpha':0.2, 'edgecolor':'k', 's':30}, ax=ax)\n",
    "    if ax_i%len(tempD2)==0:\n",
    "        plt.setp(ax, xlabel='', ylabel='Sex-mixed b'+axis_label)\n",
    "    else:\n",
    "        plt.setp(ax, xlabel='', ylabel='')\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    ##Annotate Pearson's correlation\n",
    "    pearson_r, pval = stats.pearsonr(tempDF['Sex-specific'], tempDF['Sex-mixed'])\n",
    "    r_text = str(Decimal(str(pearson_r)).quantize(Decimal('0.001'), rounding=ROUND_HALF_UP))\n",
    "    if pval==1.0:\n",
    "        pval_text = '1.0'\n",
    "    elif pval==0.0:\n",
    "        pval_text = '0.0'\n",
    "    else:\n",
    "        pval_text = f'{Decimal(str(pval)):.3E}'#Take more digits because rounding is bad here\n",
    "        significand, exponent = pval_text.split(sep='E-')\n",
    "        significand = str(Decimal(significand).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP))\n",
    "        if significand=='10.0':\n",
    "            significand = '1.0'\n",
    "            exponent = str(int(exponent)-1)\n",
    "        if int(exponent)>2:\n",
    "            pval_text = significand+r'$\\times$'+'10'+r'$^{{-{0}}}$'.format(exponent)##Font is different in r'$ $'...\n",
    "        elif int(exponent)>0:\n",
    "            pval_text = '0.'+'0'*(int(exponent)-1)+significand.replace('.', '')\n",
    "        else:\n",
    "            pval_text = significand\n",
    "    text = 'Pearson\\'s '+r'$r$'+' = '+r_text+'\\n'+r'$P$'+' = '+pval_text\n",
    "    ax.annotate(text, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top',\n",
    "                multialignment='left', fontsize='x-small', color='k')\n",
    "    ##Facet label\n",
    "    ax.set_title(sex, {'fontsize':'medium'})\n",
    "    #Save position to generate facet and legend later\n",
    "    if ax_i ==0:\n",
    "        ax0_pos = ax.get_position().bounds\n",
    "    elif ax_i==1:\n",
    "        ax1_pos = ax.get_position().bounds\n",
    "sns.despine()\n",
    "fig.text(x=(ax0_pos[0]+(ax1_pos[0]+ax1_pos[2]))/2, y=ax0_pos[1]-ax0_pos[3]*0.2,#Minor manual adjustment\n",
    "         s='Sex-specific b'+axis_label, fontsize='medium',\n",
    "         verticalalignment='top', horizontalalignment='center', rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check consistency of the baseline predictions\n",
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'Both sex':predictDF_B}\n",
    "tempD2 = {'Female':'Female', 'Male':'Male', 'Both sex':'BothSex'}\n",
    "yvar_model = 'ChemBMI'\n",
    "axis_label = 'BMI [kg m'+r'$^{-2}$'+']'\n",
    "\n",
    "tempD = {}\n",
    "for sex in tempD2.keys():\n",
    "    #Retrieve the baseline predictions\n",
    "    tempDF = tempD1[sex]\n",
    "    tempDF = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "    tempDF = tempDF.drop_duplicates('public_client_id', keep='first')\n",
    "    tempDF = tempDF.reset_index().set_index('public_client_id')\n",
    "    tempS1 = tempDF['Base'+yvar_model]\n",
    "    tempS1.name = 'Current'\n",
    "    \n",
    "    #Import the previous baseline prediction DF\n",
    "    fileDir = './ExportData/'\n",
    "    ipynbName = '220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_'\n",
    "    fileName = yvar_model+'-'+tempD2[sex]+'.tsv'\n",
    "    tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id':str})\n",
    "    tempDF = tempDF.set_index('public_client_id')\n",
    "    tempS2 = tempDF['Base'+yvar_model]\n",
    "    tempS2.name = 'Previous'\n",
    "    \n",
    "    tempDF = pd.merge(tempS1, tempS2, left_index=True, right_index=True, how='outer')\n",
    "    tempD[sex] = tempDF\n",
    "    \n",
    "    #Check exact values\n",
    "    print(sex)\n",
    "    print(' - Participant is consistent:', len(tempDF)==len(tempDF.dropna()))\n",
    "    tempDF1 = tempDF.loc[tempDF['Current']!=tempDF['Previous']]\n",
    "    print(' - Inconsistent baseline predictions:',\n",
    "          len(tempDF1), '(', len(tempDF1)/len(tempDF)*100, '[%])')\n",
    "    display(tempDF1)\n",
    "    \n",
    "    #Check obesity classification\n",
    "    for bbmi in ['Current', 'Previous']:\n",
    "        tempL = []\n",
    "        for value in tempDF[bbmi].tolist():\n",
    "            if np.isnan(value):\n",
    "                tempL.append('NotCalculated')\n",
    "            elif value < 18.5:\n",
    "                tempL.append('Underweight')\n",
    "            elif value < 25:\n",
    "                tempL.append('Normal')\n",
    "            elif value < 30:\n",
    "                tempL.append('Overweight')\n",
    "            elif value >= 30:\n",
    "                tempL.append('Obese')\n",
    "            else:#Just in case\n",
    "                tempL.append('Error?')\n",
    "        tempDF[bbmi+'_Base'+yvar_model+'_class'] = tempL\n",
    "        print(' - '+bbmi+'_Base'+yvar_model+'_class:')\n",
    "        tempS = tempDF[bbmi+'_Base'+yvar_model+'_class'].value_counts()\n",
    "        tempDF1 = pd.DataFrame({'Count':tempS, 'Percentage':tempS/len(tempDF)*100})\n",
    "        display(tempDF1)\n",
    "\n",
    "#Plot current vs. previous baseline predictions per model\n",
    "tempD2 = {'Female':'tab:red', 'Male':'tab:blue', 'Both sex':'tab:green'}\n",
    "range_min = np.min([df[var].min() for df in tempD.values() for var in ['Current', 'Previous']])\n",
    "range_max = np.max([df[var].max() for df in tempD.values() for var in ['Current', 'Previous']])\n",
    "sns.set(style='ticks', font='Arial', context='talk')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(tempD2), figsize=(10, 3), sharex=True, sharey=True,\n",
    "                         gridspec_kw={'hspace':0.1, 'wspace':0.1})\n",
    "for ax_i, ax in enumerate(axes.flat):\n",
    "    sex = list(tempD2.keys())[ax_i]\n",
    "    tempDF = tempD[sex]\n",
    "    #Y=X as reference\n",
    "    ax.plot([range_min, range_max], [range_min, range_max], color='black', linestyle=(0, (1, 2)))\n",
    "    #Regplot\n",
    "    sns.regplot(data=tempDF, x='Previous', y='Current', color=tempD2[sex],\n",
    "                scatter=True, fit_reg=True, ci=95, truncate=False, marker='o',\n",
    "                scatter_kws={'alpha':0.2, 'edgecolor':'k', 's':30}, ax=ax)\n",
    "    if ax_i%len(tempD2)==0:\n",
    "        plt.setp(ax, xlabel='', ylabel='Current b'+axis_label)\n",
    "    else:\n",
    "        plt.setp(ax, xlabel='', ylabel='')\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    ##Annotate Pearson's correlation\n",
    "    pearson_r, pval = stats.pearsonr(tempDF['Previous'], tempDF['Current'])\n",
    "    r_text = str(Decimal(str(pearson_r)).quantize(Decimal('0.001'), rounding=ROUND_HALF_UP))\n",
    "    if pval==1.0:\n",
    "        pval_text = '1.0'\n",
    "    elif pval==0.0:\n",
    "        pval_text = '0.0'\n",
    "    else:\n",
    "        pval_text = f'{Decimal(str(pval)):.3E}'#Take more digits because rounding is bad here\n",
    "        significand, exponent = pval_text.split(sep='E-')\n",
    "        significand = str(Decimal(significand).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP))\n",
    "        if significand=='10.0':\n",
    "            significand = '1.0'\n",
    "            exponent = str(int(exponent)-1)\n",
    "        if int(exponent)>2:\n",
    "            pval_text = significand+r'$\\times$'+'10'+r'$^{{-{0}}}$'.format(exponent)##Font is different in r'$ $'...\n",
    "        elif int(exponent)>0:\n",
    "            pval_text = '0.'+'0'*(int(exponent)-1)+significand.replace('.', '')\n",
    "        else:\n",
    "            pval_text = significand\n",
    "    text = 'Pearson\\'s '+r'$r$'+' = '+r_text+'\\n'+r'$P$'+' = '+pval_text\n",
    "    ax.annotate(text, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top',\n",
    "                multialignment='left', fontsize='x-small', color='k')\n",
    "    ##Facet label\n",
    "    ax.set_title(sex, {'fontsize':'medium'})\n",
    "    #Save position to generate facet and legend later\n",
    "    if ax_i ==0:\n",
    "        ax0_pos = ax.get_position().bounds\n",
    "    elif ax_i==2:\n",
    "        ax2_pos = ax.get_position().bounds\n",
    "sns.despine()\n",
    "fig.text(x=(ax0_pos[0]+(ax2_pos[0]+ax2_pos[2]))/2, y=ax0_pos[1]-ax0_pos[3]*0.2,#Minor manual adjustment\n",
    "         s='Previous b'+axis_label, fontsize='medium',\n",
    "         verticalalignment='top', horizontalalignment='center', rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> The inconsistent predictions were the same values (at least) until six decimal places, probably due to floating issues. In fact, bBMI class is surely consisistent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combined omics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. Prepare the cleaned omics dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Because the fitted models are used for predictions, the dependent variable (BMI) is not needed. (Of note, BMI was not necessarily available for the same point of omics measurements.) However, not only the time-series but also the baseline omics DF needs to be prepared for standardization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = 'combiDF'\n",
    "\n",
    "#Import the cleaned baseline omics dataframes\n",
    "fileDir = '../210104_Biological-BMI-paper/ExportData/'\n",
    "ipynbName = '210104_Biological-BMI-paper_RF-imputation_'\n",
    "fileName = 'baseline-'+df_n+'-with-RF-imputation.tsv'\n",
    "tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id': str})\n",
    "tempDF = tempDF.set_index('public_client_id')\n",
    "print(df_n+' original shape:', tempDF.shape)\n",
    "\n",
    "#Drop BMI and covariates\n",
    "tempL = ['log_BaseBMI', 'Sex', 'BaseAge', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Race']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF)\n",
    "\n",
    "baseDF = tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = 'combiDF'\n",
    "\n",
    "#Import the cleaned time-series omics dataframes\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220804_Multiomics-BMI-NatMed1stRevision_RF-imputation-ver2_'\n",
    "fileName = 'time-series-'+df_n+'-with-RF-imputation.tsv'\n",
    "tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id': str})\n",
    "tempDF = tempDF.set_index('KeyIndex')\n",
    "tempDF = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "print(df_n+' original shape:', tempDF.shape)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "\n",
    "#Drop BMI and covariates\n",
    "tempL = ['log_BaseBMI', 'Sex', 'BaseAge', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'Race']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "\n",
    "tsDF = tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check consistency\n",
    "print('Baseline DF:')\n",
    "display(baseDF.describe())\n",
    "print('Baseline from the time-series DF:')\n",
    "tempDF = tsDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "tempDF = tempDF.drop_duplicates('public_client_id', keep='first')\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "tempDF = tempDF.drop(columns=tempL)\n",
    "display(tempDF.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> Confirmed that the baseline measurements were consistent after the improved imputation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. Standarization with the baseline distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "\n",
    "#Check just in case\n",
    "tempA1 = baseDF.columns.to_numpy()\n",
    "tempA2 = tsDF.drop(columns=tempL).columns.to_numpy()\n",
    "print('nVariables is consistent between baseline and time-series DFs:',\n",
    "      len(tempA1)==len(tempA2))\n",
    "print('Variable order is consistent between baseline and time-series DFs:',\n",
    "      (tempA1==tempA2).sum()==len(tempA1))\n",
    "\n",
    "tempD2 = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    tempL1 = tempDF.index.tolist()\n",
    "    #Prepare baseline DF\n",
    "    tempDF1 = baseDF.loc[tempL1]\n",
    "    #Compute the mean and std for Z-score transformation based on the baseline distribution\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    scaler.fit(tempDF1)#Column direction\n",
    "    #Z-score transformation of the baseline DF (just for confirmation)\n",
    "    tempA = scaler.transform(tempDF1)\n",
    "    tempDF1 = pd.DataFrame(data=tempA, index=tempDF1.index, columns=tempDF1.columns)\n",
    "    \n",
    "    #Prepare time-series DF\n",
    "    tempDF2 = tsDF.loc[tsDF['public_client_id'].isin(tempL1)]\n",
    "    tempDF = tempDF2.drop(columns=tempL)\n",
    "    #Z-score transformation of the time-series DF with the baseline distribution\n",
    "    tempA = scaler.transform(tempDF)\n",
    "    tempDF = pd.DataFrame(data=tempA, index=tempDF.index, columns=tempDF.columns)\n",
    "    #Recover the time-series metadata\n",
    "    tempDF2 = tempDF2[tempL]\n",
    "    tempDF2 = pd.merge(tempDF2, tempDF, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    print(sex)\n",
    "    display(tempDF2)\n",
    "    tempD2[sex] = tempDF2\n",
    "    \n",
    "    #Confirmation\n",
    "    tempD = {'Baseline DF':tempDF1, 'Time-series DF':tempDF2}\n",
    "    for df_n in tempD.keys():\n",
    "        tempDF = tempD[df_n]\n",
    "        print(' - '+df_n, tempDF.shape)\n",
    "        if df_n=='Time-series DF':\n",
    "            print('    -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "            tempDF = tempDF.drop(columns=tempL)\n",
    "        display(tempDF.describe())\n",
    "        sns.set(style='ticks', font='Arial', context='notebook')\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        for col_i in range(3):\n",
    "            sns.distplot(tempDF.iloc[:, col_i], label=tempDF.columns[col_i])\n",
    "        sns.despine()\n",
    "        plt.xlabel(r'$Z$'+'-score')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend(bbox_to_anchor=(1, 0.5), loc='center left', borderaxespad=1)\n",
    "        plt.show()\n",
    "    print('')\n",
    "\n",
    "tsDF_F = tempD2['Female']\n",
    "tsDF_M = tempD2['Male']\n",
    "tsDF_B = tempD2['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> Confirmed that the baseline summary was completely same with the before (the baseline LASSO modeling).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3. Import the fitted LASSO models with the baseline measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar_model = 'CombiBMI'\n",
    "tempD = {}\n",
    "for sex in ['Female', 'Male', 'BothSex']:\n",
    "    #Import the LASSO beta-coefficients (including intercept)\n",
    "    fileDir = './ExportData/'\n",
    "    ipynbName = '220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_'\n",
    "    fileName = yvar_model+'-'+sex+'-LASSObcoefs.tsv'\n",
    "    tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t').set_index('Variable')\n",
    "    #Drop summary columns\n",
    "    tempL = ['Mean', 'SD', 'nZeros']\n",
    "    tempDF = tempDF.drop(columns=tempL)\n",
    "    tempD[sex] = tempDF\n",
    "    \n",
    "    #Check\n",
    "    print(sex+':')\n",
    "    print(' - Variables (without intercept):', len(tempDF)-1)\n",
    "    display(tempDF)\n",
    "    print('')\n",
    "\n",
    "modelDF_F = tempD['Female']\n",
    "modelDF_M = tempD['Male']\n",
    "modelDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-4. Calculate predictions using the fitted models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> According to LassoCV source, the self.predict(X) method calls self._decision_function(X) method, which further returns “safe_sparsedot(X, self.coef.T, denseoutput=True) + self.intercept\". In this case, safe_sparse_dot() simply corresponds to a dot product. Hence, manual calculation from beta-coefficients and intercept is impremented here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':tsDF_F, 'Male':tsDF_M, 'BothSex':tsDF_B}\n",
    "tempD2 = {'Female':modelDF_F, 'Male':modelDF_M, 'BothSex':modelDF_B}\n",
    "tempL = ['public_client_id', 'days_in_program', 'Season']\n",
    "\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    tempDF1 = tempDF.drop(columns=tempL)\n",
    "    tempDF2 = tempD2[sex]\n",
    "    \n",
    "    #Add dummy intercept variable to data DF\n",
    "    tempDF1['Intercept'] = 1.0\n",
    "    \n",
    "    #Check just in case\n",
    "    tempA1 = tempDF1.columns.to_numpy()\n",
    "    tempA2 = tempDF2.index.to_numpy()\n",
    "    print(sex)\n",
    "    print(' - nVariables is consistent between data and model DFs:',\n",
    "          len(tempA1)==len(tempA2))\n",
    "    print(' - Variable order is consistent between data and model DFs:',\n",
    "          (tempA1==tempA2).sum()==len(tempA1))\n",
    "    \n",
    "    #Calculate prediction\n",
    "    tempA = np.dot(tempDF1, tempDF2)\n",
    "    tempDF1 = pd.DataFrame(tempA, index=tempDF1.index, columns=tempDF2.columns)\n",
    "    \n",
    "    #Recover the time-series metadata\n",
    "    tempDF = tempDF[tempL]\n",
    "    tempDF = pd.merge(tempDF, tempDF1, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    tempD[sex] = tempDF\n",
    "    display(tempDF)\n",
    "    print('')\n",
    "\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To obtain one single prediction for each participant and each time point, the calculated predictions from each model can be averaged.  \n",
    "> ***–> However, in addition to the overfitting problem for the baseline predictions, there is a potential risk of data leakage even for the longitudinal predictions.***  \n",
    "> –> In this version, one single prediction for each participant and each time point is selected with the prediction from the model for which the participant was included in the baseline testing (hold-out) set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "tempD2 = {'Female':predictDF_F, 'Male':predictDF_M, 'BothSex':predictDF_B}\n",
    "yvar_model = 'CombiBMI'\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    #Retrieve the predictions for the testing (hold-out) set\n",
    "    tempDF = tempD1[sex]\n",
    "    tempS = tempDF['Testing']\n",
    "    tempDF = tempD2[sex]\n",
    "    tempDF = pd.merge(tempDF, tempS, left_on='public_client_id', right_index=True, how='left')\n",
    "    tempL = []\n",
    "    for row_i in range(len(tempDF)):\n",
    "        model_n = tempDF['Testing'].iloc[row_i]\n",
    "        tempL.append(tempDF[model_n].iloc[row_i])\n",
    "    tempDF['log_'+yvar_model] = tempL\n",
    "    \n",
    "    #Drop the temporal prediction columns\n",
    "    tempDF = tempDF.loc[:, ~tempDF.columns.str.contains('Model_')]\n",
    "    \n",
    "    #Convert to original scale\n",
    "    tempDF[yvar_model] = np.e**tempDF['log_'+yvar_model]\n",
    "    \n",
    "    tempD[sex] = tempDF\n",
    "    print(sex)\n",
    "    display(tempDF)\n",
    "    print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "    print('')\n",
    "#Update\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-5. Clean and save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the baseline info\n",
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'BothSex':predictDF_B}\n",
    "tempD2 = {'Female':bmiDF_F, 'Male':bmiDF_M, 'BothSex':bmiDF_B}\n",
    "yvar_model = 'CombiBMI'\n",
    "tempD = {}\n",
    "for sex in tempD1.keys():\n",
    "    tempDF = tempD1[sex]\n",
    "    \n",
    "    #Retrieve the baseline predictions\n",
    "    tempDF1 = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "    tempDF1 = tempDF1.drop_duplicates('public_client_id', keep='first')\n",
    "    tempDF1 = tempDF1.reset_index().set_index('public_client_id')\n",
    "    tempDF1 = tempDF1.rename(columns={yvar_model:'Base'+yvar_model})\n",
    "    \n",
    "    #Add baseline BMI and covariate info\n",
    "    tempDF2 = tempD2[sex]\n",
    "    ##Replace the log-scaled BMI with the original scaled\n",
    "    tempS = np.e**tempDF2['log_BaseBMI']\n",
    "    tempS.name = 'BaseBMI'\n",
    "    tempDF2 = pd.merge(tempS, tempDF2, left_index=True, right_index=True, how='left')\n",
    "    tempDF2 = tempDF2.drop(columns=['log_BaseBMI', 'Testing'])\n",
    "    tempDF1 = pd.merge(tempDF1['Base'+yvar_model], tempDF2,\n",
    "                       left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    #Obesity classification\n",
    "    for bmi in ['BMI', yvar_model]:\n",
    "        tempL = []\n",
    "        for value in tempDF1['Base'+bmi].tolist():\n",
    "            if np.isnan(value):\n",
    "                tempL.append('NotCalculated')\n",
    "            elif value < 18.5:\n",
    "                tempL.append('Underweight')\n",
    "            elif value < 25:\n",
    "                tempL.append('Normal')\n",
    "            elif value < 30:\n",
    "                tempL.append('Overweight')\n",
    "            elif value >= 30:\n",
    "                tempL.append('Obese')\n",
    "            else:#Just in case\n",
    "                tempL.append('Error?')\n",
    "        tempDF1['Base'+bmi+'_class'] = tempL\n",
    "    \n",
    "    #Check baseline summary\n",
    "    print(sex+' baseline summary:')\n",
    "    display(tempDF1.describe(include='all'))\n",
    "    for bmi in ['BMI', yvar_model]:\n",
    "        print('Base'+bmi+'_class:')\n",
    "        tempS1 = tempDF1['Base'+bmi+'_class'].value_counts()\n",
    "        tempDF2 = pd.DataFrame({'Count':tempS1, 'Percentage':tempS1/len(tempDF1)*100})\n",
    "        display(tempDF2)\n",
    "    \n",
    "    #Merge\n",
    "    tempDF = pd.merge(tempDF, tempDF1, left_on='public_client_id', right_index=True, how='left')\n",
    "    tempD[sex] = tempDF\n",
    "    display(tempDF)\n",
    "    print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "    print('')\n",
    "#Update\n",
    "predictDF_F = tempD['Female']\n",
    "predictDF_M = tempD['Male']\n",
    "predictDF_B = tempD['BothSex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save\n",
    "yvar_model = 'CombiBMI'\n",
    "\n",
    "#Sex-stratified models\n",
    "tempDF = pd.concat([predictDF_F, predictDF_M], axis=0)\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220805_Multiomics-BMI-NatMed1stRevision_BMI-longitudinal-LASSO_'\n",
    "fileName = yvar_model+'-FemaleMale.tsv'\n",
    "tempDF.to_csv(fileDir+ipynbName+fileName, sep='\\t', index=True)\n",
    "\n",
    "#Sex-mixed model\n",
    "tempDF = predictDF_B\n",
    "display(tempDF)\n",
    "print(' -> Unique ID:', len(tempDF['public_client_id'].unique()))\n",
    "fileDir = './ExportData/'\n",
    "ipynbName = '220805_Multiomics-BMI-NatMed1stRevision_BMI-longitudinal-LASSO_'\n",
    "fileName = yvar_model+'-BothSex.tsv'\n",
    "tempDF.to_csv(fileDir+ipynbName+fileName, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-6. Check consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'Both sex':predictDF_B}\n",
    "yvar_model = 'CombiBMI'\n",
    "axis_label = 'BMI [kg m'+r'$^{-2}$'+']'\n",
    "\n",
    "#Plot difference b/w sex-specific and sex-mixed models\n",
    "tempD2 = {'Female':'tab:red', 'Male':'tab:blue'}\n",
    "range_min = np.min([df[var].min() for df in tempD1.values() for var in [yvar_model]])\n",
    "range_max = np.max([df[var].max() for df in tempD1.values() for var in [yvar_model]])\n",
    "sns.set(style='ticks', font='Arial', context='talk')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(tempD2), figsize=(6.5, 3), sharex=True, sharey=True,\n",
    "                         gridspec_kw={'hspace':0.1, 'wspace':0.1})\n",
    "for ax_i, ax in enumerate(axes.flat):\n",
    "    sex = list(tempD2.keys())[ax_i]\n",
    "    #Prepare DF\n",
    "    tempS1 = tempD1[sex][yvar_model]\n",
    "    tempS1.name = 'Sex-specific'\n",
    "    tempS2 = tempD1['Both sex'][yvar_model]\n",
    "    tempS2.name = 'Sex-mixed'\n",
    "    tempDF = pd.merge(tempS1, tempS2, left_index=True, right_index=True, how='inner')\n",
    "    #Y=X as reference\n",
    "    ax.plot([range_min, range_max], [range_min, range_max], color='black', linestyle=(0, (1, 2)))\n",
    "    #Regplot\n",
    "    sns.regplot(data=tempDF, x='Sex-specific', y='Sex-mixed', color=tempD2[sex],\n",
    "                scatter=True, fit_reg=True, ci=95, truncate=False, marker='o',\n",
    "                scatter_kws={'alpha':0.2, 'edgecolor':'k', 's':30}, ax=ax)\n",
    "    if ax_i%len(tempD2)==0:\n",
    "        plt.setp(ax, xlabel='', ylabel='Sex-mixed b'+axis_label)\n",
    "    else:\n",
    "        plt.setp(ax, xlabel='', ylabel='')\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    ##Annotate Pearson's correlation\n",
    "    pearson_r, pval = stats.pearsonr(tempDF['Sex-specific'], tempDF['Sex-mixed'])\n",
    "    r_text = str(Decimal(str(pearson_r)).quantize(Decimal('0.001'), rounding=ROUND_HALF_UP))\n",
    "    if pval==1.0:\n",
    "        pval_text = '1.0'\n",
    "    elif pval==0.0:\n",
    "        pval_text = '0.0'\n",
    "    else:\n",
    "        pval_text = f'{Decimal(str(pval)):.3E}'#Take more digits because rounding is bad here\n",
    "        significand, exponent = pval_text.split(sep='E-')\n",
    "        significand = str(Decimal(significand).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP))\n",
    "        if significand=='10.0':\n",
    "            significand = '1.0'\n",
    "            exponent = str(int(exponent)-1)\n",
    "        if int(exponent)>2:\n",
    "            pval_text = significand+r'$\\times$'+'10'+r'$^{{-{0}}}$'.format(exponent)##Font is different in r'$ $'...\n",
    "        elif int(exponent)>0:\n",
    "            pval_text = '0.'+'0'*(int(exponent)-1)+significand.replace('.', '')\n",
    "        else:\n",
    "            pval_text = significand\n",
    "    text = 'Pearson\\'s '+r'$r$'+' = '+r_text+'\\n'+r'$P$'+' = '+pval_text\n",
    "    ax.annotate(text, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top',\n",
    "                multialignment='left', fontsize='x-small', color='k')\n",
    "    ##Facet label\n",
    "    ax.set_title(sex, {'fontsize':'medium'})\n",
    "    #Save position to generate facet and legend later\n",
    "    if ax_i ==0:\n",
    "        ax0_pos = ax.get_position().bounds\n",
    "    elif ax_i==1:\n",
    "        ax1_pos = ax.get_position().bounds\n",
    "sns.despine()\n",
    "fig.text(x=(ax0_pos[0]+(ax1_pos[0]+ax1_pos[2]))/2, y=ax0_pos[1]-ax0_pos[3]*0.2,#Minor manual adjustment\n",
    "         s='Sex-specific b'+axis_label, fontsize='medium',\n",
    "         verticalalignment='top', horizontalalignment='center', rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check consistency of the baseline predictions\n",
    "tempD1 = {'Female':predictDF_F, 'Male':predictDF_M, 'Both sex':predictDF_B}\n",
    "tempD2 = {'Female':'Female', 'Male':'Male', 'Both sex':'BothSex'}\n",
    "yvar_model = 'CombiBMI'\n",
    "axis_label = 'BMI [kg m'+r'$^{-2}$'+']'\n",
    "\n",
    "tempD = {}\n",
    "for sex in tempD2.keys():\n",
    "    #Retrieve the baseline predictions\n",
    "    tempDF = tempD1[sex]\n",
    "    tempDF = tempDF.sort_values(by=['public_client_id', 'days_in_program'], ascending=True)\n",
    "    tempDF = tempDF.drop_duplicates('public_client_id', keep='first')\n",
    "    tempDF = tempDF.reset_index().set_index('public_client_id')\n",
    "    tempS1 = tempDF['Base'+yvar_model]\n",
    "    tempS1.name = 'Current'\n",
    "    \n",
    "    #Import the previous baseline prediction DF\n",
    "    fileDir = './ExportData/'\n",
    "    ipynbName = '220801_Multiomics-BMI-NatMed1stRevision_BMI-baseline-LASSO_'\n",
    "    fileName = yvar_model+'-'+tempD2[sex]+'.tsv'\n",
    "    tempDF = pd.read_csv(fileDir+ipynbName+fileName, sep='\\t', dtype={'public_client_id':str})\n",
    "    tempDF = tempDF.set_index('public_client_id')\n",
    "    tempS2 = tempDF['Base'+yvar_model]\n",
    "    tempS2.name = 'Previous'\n",
    "    \n",
    "    tempDF = pd.merge(tempS1, tempS2, left_index=True, right_index=True, how='outer')\n",
    "    tempD[sex] = tempDF\n",
    "    \n",
    "    #Check exact values\n",
    "    print(sex)\n",
    "    print(' - Participant is consistent:', len(tempDF)==len(tempDF.dropna()))\n",
    "    tempDF1 = tempDF.loc[tempDF['Current']!=tempDF['Previous']]\n",
    "    print(' - Inconsistent baseline predictions:',\n",
    "          len(tempDF1), '(', len(tempDF1)/len(tempDF)*100, '[%])')\n",
    "    display(tempDF1)\n",
    "    \n",
    "    #Check obesity classification\n",
    "    for bbmi in ['Current', 'Previous']:\n",
    "        tempL = []\n",
    "        for value in tempDF[bbmi].tolist():\n",
    "            if np.isnan(value):\n",
    "                tempL.append('NotCalculated')\n",
    "            elif value < 18.5:\n",
    "                tempL.append('Underweight')\n",
    "            elif value < 25:\n",
    "                tempL.append('Normal')\n",
    "            elif value < 30:\n",
    "                tempL.append('Overweight')\n",
    "            elif value >= 30:\n",
    "                tempL.append('Obese')\n",
    "            else:#Just in case\n",
    "                tempL.append('Error?')\n",
    "        tempDF[bbmi+'_Base'+yvar_model+'_class'] = tempL\n",
    "        print(' - '+bbmi+'_Base'+yvar_model+'_class:')\n",
    "        tempS = tempDF[bbmi+'_Base'+yvar_model+'_class'].value_counts()\n",
    "        tempDF1 = pd.DataFrame({'Count':tempS, 'Percentage':tempS/len(tempDF)*100})\n",
    "        display(tempDF1)\n",
    "\n",
    "#Plot current vs. previous baseline predictions per model\n",
    "tempD2 = {'Female':'tab:red', 'Male':'tab:blue', 'Both sex':'tab:green'}\n",
    "range_min = np.min([df[var].min() for df in tempD.values() for var in ['Current', 'Previous']])\n",
    "range_max = np.max([df[var].max() for df in tempD.values() for var in ['Current', 'Previous']])\n",
    "sns.set(style='ticks', font='Arial', context='talk')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(tempD2), figsize=(10, 3), sharex=True, sharey=True,\n",
    "                         gridspec_kw={'hspace':0.1, 'wspace':0.1})\n",
    "for ax_i, ax in enumerate(axes.flat):\n",
    "    sex = list(tempD2.keys())[ax_i]\n",
    "    tempDF = tempD[sex]\n",
    "    #Y=X as reference\n",
    "    ax.plot([range_min, range_max], [range_min, range_max], color='black', linestyle=(0, (1, 2)))\n",
    "    #Regplot\n",
    "    sns.regplot(data=tempDF, x='Previous', y='Current', color=tempD2[sex],\n",
    "                scatter=True, fit_reg=True, ci=95, truncate=False, marker='o',\n",
    "                scatter_kws={'alpha':0.2, 'edgecolor':'k', 's':30}, ax=ax)\n",
    "    if ax_i%len(tempD2)==0:\n",
    "        plt.setp(ax, xlabel='', ylabel='Current b'+axis_label)\n",
    "    else:\n",
    "        plt.setp(ax, xlabel='', ylabel='')\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "    ##Annotate Pearson's correlation\n",
    "    pearson_r, pval = stats.pearsonr(tempDF['Previous'], tempDF['Current'])\n",
    "    r_text = str(Decimal(str(pearson_r)).quantize(Decimal('0.001'), rounding=ROUND_HALF_UP))\n",
    "    if pval==1.0:\n",
    "        pval_text = '1.0'\n",
    "    elif pval==0.0:\n",
    "        pval_text = '0.0'\n",
    "    else:\n",
    "        pval_text = f'{Decimal(str(pval)):.3E}'#Take more digits because rounding is bad here\n",
    "        significand, exponent = pval_text.split(sep='E-')\n",
    "        significand = str(Decimal(significand).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP))\n",
    "        if significand=='10.0':\n",
    "            significand = '1.0'\n",
    "            exponent = str(int(exponent)-1)\n",
    "        if int(exponent)>2:\n",
    "            pval_text = significand+r'$\\times$'+'10'+r'$^{{-{0}}}$'.format(exponent)##Font is different in r'$ $'...\n",
    "        elif int(exponent)>0:\n",
    "            pval_text = '0.'+'0'*(int(exponent)-1)+significand.replace('.', '')\n",
    "        else:\n",
    "            pval_text = significand\n",
    "    text = 'Pearson\\'s '+r'$r$'+' = '+r_text+'\\n'+r'$P$'+' = '+pval_text\n",
    "    ax.annotate(text, xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                horizontalalignment='left', verticalalignment='top',\n",
    "                multialignment='left', fontsize='x-small', color='k')\n",
    "    ##Facet label\n",
    "    ax.set_title(sex, {'fontsize':'medium'})\n",
    "    #Save position to generate facet and legend later\n",
    "    if ax_i ==0:\n",
    "        ax0_pos = ax.get_position().bounds\n",
    "    elif ax_i==2:\n",
    "        ax2_pos = ax.get_position().bounds\n",
    "sns.despine()\n",
    "fig.text(x=(ax0_pos[0]+(ax2_pos[0]+ax2_pos[2]))/2, y=ax0_pos[1]-ax0_pos[3]*0.2,#Minor manual adjustment\n",
    "         s='Previous b'+axis_label, fontsize='medium',\n",
    "         verticalalignment='top', horizontalalignment='center', rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> –> The inconsistent predictions were the same values (at least) until six decimal places, probably due to floating issues. In fact, bBMI class is surely consisistent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# — End of this notebook —"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arivale-py3 - Python",
   "language": "python",
   "name": "conda-env-arivale-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
